<<include=FALSE>>=
library(knitr)
opts_chunk$set(concordance=TRUE)
options(digits = 2)
@


<<chap3-load.data,echo=F,warning=FALSE,message=FALSE>>=
res.dp.f <- function(stat.vvs,stat.type,meth)
  {rbind(stat.vvs[unlist(v.type)[1:3],meth,],'Broker Total'=stat.type[1,meth,],
      stat.vvs[unlist(v.type)[4:8],meth,],'Stock total'=stat.type[2,meth,],
      'sec.ret'=stat.vvs[unlist(v.type)[9],meth,],
      stat.vvs[unlist(v.type)[10:13],meth,],'Macro total'=stat.type[4,meth,])
   }

eps.stat.f <- function(rank.dt,num.dt,m,type)
  {setnames(
    cbind(
    rbind(rank.dt[,.N,by=.(q.id,Sector,get(m))][,.N,by=Sector],list('Total',rank.dt[,.N,by=.(q.id,get(m))][,.N])),
        rbind(rank.dt[,.N,by=.(q.id,Sector,get(m))][,mean(N),by=Sector],list('Total',rank.dt[,.N,by=.(q.id,get(m))][,mean(N)]))[,.(V1)],
        rbind(num.dt[data.type==type][,.N,by=.(q.id,Sector,get(m))][,mean(N),by=.(Sector)],list('Total',num.dt[data.type==type][,.N,by=.(q.id,get(m))][,mean(N)]))[,V1],
        rbind(num.dt[data.type==type,mean(N),by=.(Sector,Stock,Broker)][,mean(V1),by=.(Sector,get(m))][,mean(V1),by=Sector],list('Total',num.dt[data.type==type,mean(N),by=.(Stock,Broker)][,mean(V1),by=.(get(m))][,mean(V1)]))[,V1],
        rbind(num.dt[data.type==type,.N,by=.(Sector,Broker,Stock)][,mean(N),by=.(Sector,get(m))][,mean(V1),by=Sector],list('Total',num.dt[data.type==type,.N,by=.(Broker,Stock)][,mean(N),by=.(get(m))][,mean(V1)]))[,V1]),c('Sector','Observ','Forecast',paste0(m,'s'),paste0('Forecast/',tolower(m)),'Follow time,q'))
}

population.stat.f <- function(dt)
  { rbind(setnames(dt[,c(lapply(.SD,function(i){length(unique(i))}),.N),by=.(Sector),.SDcols=c('Stock','Broker')],4,'Forecast'),setnames(cbind('Total',dt[,c(lapply(.SD,function(i){length(unique(i))}),Forecast=.N),.SDcols=c('Stock','Broker')]),1,'Sector'))
    }



methods<-c('raw','diff','random','roll.sd')
#baselines<-c('true','naive','default')
setwd('~/Dropbox/workspace/Projects/EPS/')
library(reshape2)
library(data.table)
library(ggplot2)
library(stringr)
library(zoo)
library(xtable)
library(abind)
library(scales)
library(labelRank)
source('lib/aux.functions.R')
source('lib/ranking.scripts.R')
load('cache/complete.dt.RData')
load('cache/eps.dt.RData')
load('cache/vvs.names.RData')
load('cache/metric.vvs.RData')

#set(ind.v,i=which(is.infinite(ind.v[[4L]])),4L,value=NA )
v.type <- list(vvs.names[1:3],vvs.names[4:8],vvs.names[9],vvs.names[10:13])

data.to.display <- c('Variable','method','Stock','nbr.val','mean', 'median','std.dev')

desc.ind <- setnames(metric.vvs[,list(length(unique(Stock)),.N,mean(value,na.rm=T),median(value,na.rm=T),sd(value,na.rm=T)),by=.(vvs,method)],data.to.display)

m.ind.vvs <- acast(melt(desc.ind,id.vars=c('Variable','method')),Variable~method~variable,value.var='value')

setkey(eps.dt,Sector)
setkey(complete.dt,Sector)
stat.eps <- population.stat.f(eps.dt)

sample.stat.eps <- population.stat.f(complete.dt)


num.f.dt <- rbind(eps.dt[,.N,by=.(q.id,Sector,Broker,Stock)][,data.type:='sample'],complete.dt[,.N,by=.(q.id,Sector,Broker,Stock)][,data.type:='filtered'])



per.broker <- eps.stat.f(eps.dt,num.f.dt,'Broker','sample')
filter.per.broker <- eps.stat.f(complete.dt,num.f.dt,'Broker','filtered')
per.stock <- eps.stat.f(eps.dt,num.f.dt,'Stock','sample')
filter.per.stock <- eps.stat.f(complete.dt,num.f.dt,'Stock','filtered')


metric.vvs$vvs.type <- factor(metric.vvs$vvs.type,levels=c('brok','stock','sector','macro'))


stat.vvs <- acast(melt(na.omit(metric.vvs)[,list(median(metric),mean(metric),sd(metric)),by=.(vvs,method)],id.vars=c('vvs','method')),vvs~method~variable)



stat.type <- acast(melt(na.omit(metric.vvs)[,list(median(metric),mean(metric),sd(metric)),by=.(vvs.type,method)],id.vars=c('vvs.type','method')),vvs.type~method~variable)

res.dp <- abind(lapply(methods,function(i){res.dp.f(stat.vvs,stat.type,i)}),along=3,new.names=list(NULL,NULL,methods))


x1 <- letters[1:5]
x2 <- c('b','a','a','a','a')
#x2 <- letters[6:10]
x <- cbind(x1,x2)
y <- rbind(
  c(1,2,3,4),
  c(2,1,3,4),
  c(3,2,1,4),
  c(4,3,2,1),
  c(4,1,2,3))
model <- nbrModel(x,y,rep(1,nrow(y)))
rank.power <- rbind(melt(data.table(t(model$cond[x1,]),priors=model$priors)[,':='(vvs='x1',t=.I)],id.vars=c('vvs','priors','t')),melt(data.table(t(model$cond[x2,]),priors=model$priors)[,':='(vvs='x2',t=.I)],id.vars=c('vvs','priors','t')))[,':='(diff.x=min(abs(diff(value))),diff.rank=abs(value-priors)),by=.(vvs)][,':='(dp=sum(diff.x*diff.rank,na.rm=T)/.N,mean.diff.r=mean(diff.rank,na.rm=T)),by=.(vvs,t)]
disc.power <- unique(rank.power,by=c('vvs'))[,.(vvs,dp)]


n <- 3
n.b <- 3
eps.cont.tab <- abind(lapply(c(1,4),function(i) {cont.tab.f(complete.dt,i,n.b)}),along=3,new.names=list(NULL,NULL,c('t','t+4')))

@


\section{Introduction}
\label{ch3-sec:introduction}

The Efficient Market Hypothesis (EHM) \citep{fama1970ecm} suggests that all public information available to investors is incorporated in prices and new information is immediately reflected in valuations. Yet there are information gathering costs and financial analysts are better than an average investor at processing this information which reflects in issued buy/ sell recommendations.

These recommendations, like other news about the general economy as about the particular company, influence investors' perception and beliefs. Previous studies show that analyst stock recommendations have investment value. The literature suggests further that foreknowledge of analyst forecast accuracy is valuable \citep{brown2003}. In line with academic research findings, practitioners too pay attention to analyst forecast accuracy rankings. On an annual basis, firms such as The Institutional Investor and StarMine \footnote{http://www.starmine.com} publish analysts ratings according to how well they performed, based partly on past earnings forecast accuracy.

The importance of these ratings should not be ignored because the attention that the market gives to the recommendations of different analysts is expected to correlate with them. Typically, the performance of analysts is analyzed in terms of their individual characteristics (e.g., experience, background) \citep{clement1999}. The disadvantage of this approach is that the collection of the necessary data is difficult and it is not always reliable. As for practitioners, they rely mostly on past accuracy to predict future accuracy. In this chapter we follow an alternative approach. We characterize the general behavior of rankings of analysts using variables that characterize the context (e.g., the company in the period of interest) rather than individual analyst characteristics or past accuracy. The model we propose uses predictor variables to distinguish between more and less accurate analyst/company forecasters in different states of the world. The latter kind of data is easier to obtain (e.g., from Thomson Reuters\footnote{http://thomsonreuters.com/}) and is quite reliable. In summary, our goal is not to understand  relative performance of the analysts  in terms of their characteristics but rather in terms of the characteristics of the context in which the analysts operate.


To achieve this goal, we, first, create rankings of analyst based on the their EPS forecasts accuracy. Then, we select the state variables that, we think,  are responsible in differences of analsyts' ranks. Finaly, we apply the naive Bayes for label ranking algorithm (\ref{ch2}) to build a model that calculates a discriminative power of a variable, i.e., its the contribution to the  rankings.

We address the problem as a label ranking task, which recently has been receiving an increasing attention in the Machine Learning and Data Mining literature (e.g. \citep{hullermeier,cheng2009}). In label ranking problems,  the goal is to predict an ordering of a finite set of labels \citep{vembu2009}. In our case, the labels are the analysts and the rankings reflect their relative forecasting accuracy.  We choose to use a simple algorithm, naive Bayes for ranking \citep{aiguzhinov2010}.

The paper is organized as follows: section \ref{ch3-sec:ranking} provides the motivation for ranking the analysts; section \ref{ch3-sec:labelranking} sets up the label ranking problem and introduces the algorithms for label ranking; section \ref{ch3-sec:data} describes the datasets used for the experiments, while section \ref{ch3-sec:results} presents and discusses the results; finally, section \ref{ch3-sec:conclusion} concludes this paper.


\section{Ranking the analysts}
\label{ch3-sec:ranking}

In the finance literature there has been a long debate over the possibilities that financial analysts produce valuable financial advises. Some argue that following the advises of financial analysts projected as recommendations of buy, hold, or selling a particular stock, does not yield an abnormal return. This is consistent with EMH that states financial markets are informational efficient implying that it is not possible to implement a successful trading strategy based upon analyst stock recommendations given that the underlying information would be already reflected in the current stock prices.

The study of \cite{grossman1980iie} argues that, indeed, the point of \cite{fama1970ecm} holds and that it is likely that the markets are efficient; however, there are  information costs and the reflection of the information in the current stock prices is  not immediate as theory suggests. Due to these costs, prices cannot perfectly reflect the information which is available, since if they did, those who spent resources to obtain it would receive no compensation. Later, \cite{fama1991ecm} supports this argument.

The possibility of obtaining abnormal returns spilled out to uncountable different trading strategies over the last 50 years based upon anomalies or deviations to market efficiency. Almost all these trading strategies have one goal in common: predict future returns relying on historical prices or company characteristics. Not only there is a lot of controversy on predictability results but also many of the proposed strategies are rather difficult to implement by an average investor. The obvious alternative is to follow the recommendations of the professionals in the field, such as stock analysts or asset managers. We assume that following the best analysts is the best choice for an investor

The question of whether stock analyst recommendations bring value to investors has been around since the mid-90s. \cite{womack1996} acknowledged that there is a positive benefit for investors from following recommendations of the analysts. More recently, \cite{jegadeesh2004} suggest that only the subset of favorable recommendations has predictive power of future market returns and that the level of analyst recommendations (buy/sell) derives part of its predictive power to the fact that analysts select stocks with particular characteristics that are associated with higher returns.


Assuming that stock analyst recommendations, on average, do create value to investors \citep{womack1996,barber2001}, it is possible to create rankings of the analysts based on their forecasting accuracy or predictive power of future returns. In fact, StarMine\textsuperscript{\textregistered}
does exactly this: it ranks analysts on an annual basis and publishes the rankings worldwide. StarMine ratings serve to the benefits of the analysts in the areas of personal reputation, prestige, and compensation. These ratings may also affect how markets react to recommendations and a top-ranked analyst publishes a research report it is expected to have a greater effect than one who is ranked lower.

The StarMine ranking methodology is based on the analysts performance. This performance is measured by comparing the non-leveraged portfolio for each analysts based on his/her recommendations. The portfolio is constructed as follows. For each ``Buy'' recommendation, the portfolio is one unit long the stock and simultaneously one unit short the benchmark \footnote{Comparable index}. ``Strong buy'' gets a larger investment of two units long the stock and two units short the benchmark. ``Holds'' invest one unit in the benchmark (i.e., for an excess return of zero). Sell are the reverse. StarMine re-balances its calculations at the end of each month to adjust for when an analyst changes his or her mind (by adding, dropping or altering a rating) or when a stock enters or exits an industry grouping.

StarMine also ranks the analysts based on the accuracy of the earnings forecasts. For that, StarMine developed a proprietary metric called Single-stock Estimating Score (SES). It measures the relative accuracy of each analyst's earnings when compared against their peers.
The score from this metric ranges from 0 to 100, with 50 representing the average analyst. To get a score higher than 50, the analyst must make estimates that are both significantly different from and more accurate than other analysts' estimates.

The value of rankings such as StarMine Ratings for investors is arguable given that these are ex-post and a good analyst on one year does not necessarily make equally good recommendations in the following year. However, if one could predict the ranking of analysts ahead of time (even if with some estimation error) then it would be possible to create a successful trading strategy. \cite{brown2003} show that foreknowledge of analyst forecast accuracy is indeed valuable.

Existing approaches to predict the future performance of the analysts are based on analysts' individual characteristics \citep{clement1999} and their past accuracy \citep{brown2001}. In this paper we follow a different approach in which we predict the rankings of the financial analysts based upon state variables.\footnote{The implementation of the predicted results into a trading strategy is out of scope of this paper.}


\section{Label ranking}
\label{ch3-sec:labelranking}

Based on \cite{vembu2009}, a label ranking problem is defined as follows. Let $\mathcal{X} \subseteq \{\mathcal{V}_1,\ldots,\mathcal{V}_m\}$ be an instance space of nominal variables, such that $\mathcal{V}_a=\{v_{a,1}, \ldots, v_{a,n_a}\}$ is the domain of nominal variable $a$, containing $n_a$ different values.  Also, let $\mathcal{L} = \{\lambda_1,\ldots,\lambda_k\}$ be a set of labels, and $\mathcal{Y} = \Pi_{\mathcal{L}}$ be the output space of all possible total orders \footnote{A total order is a complete, transitive, and asymmetric relation $\succ$ on $\mathcal{L}$, where $\lambda_i \succ \lambda_j$ indicates that $\lambda_i$ precedes $\lambda_j$. In this paper, given $\mathcal{L}=\{A,B,C\}$, we will use the notation $\{A,C,B\}$ and $\{1,3,2\}$ interchangeably to represent the order $A \succ C \succ B$.}  over $\mathcal{L}$ defined on the permutation space $\Pi$. The goal of a label ranking algorithm is to learn a mapping $h: \mathcal{X} \rightarrow \mathcal{Y}$, where $h$ is chosen from a given hypothesis space $\mathcal{H}$, such that a predefined loss function $\ell: \mathcal{H} \times \mathcal{Y} \times \mathcal{Y} \rightarrow \mathbb{R}$ is minimized. The algorithm learns $h$ from a training set $\mathcal{T}=\{x_i,y_i\}_{i \in \{1, \ldots, n\}} \subseteq \mathcal{X} \times \mathcal{Y}$ of $n$ examples, where $x_i = \{x_{i,1}, x_{i,2}, \ldots, x_{i,m} \} \in \mathcal{X}$ and $ y_i = \{y_{i,1}, y_{i,2}, \dots, y_{i,k}\} \in \Pi_{\mathcal{L}}$. Furthermore, we define $y_i^{-1} = \{y_{i,1}^{-1}, y_{i,2}^{-1}, \ldots, y_{i,k}^{-1}\}$ as the order of the labels in example $i$. Given that we are focusing on total orders, $y_i^{-1}$ is a permutation of the set $\{1, 2, \ldots, k\}$ where $y_{i,j}^{-1}$ is the rank of label $\lambda_j$ in example $i$.


To assess the accuracy of the predicted rankings relative to the corresponding target rankings, a suitable loss function is needed. In this paper we compare two rankings using the Spearman correlation coefficient \cite{brazdil2003,vembu2009}:
\begin{equation}
\label{ch3-eq00}
 \rho(\pi,\hat{\pi})=1-\frac{6\sum_{j=1}^k(\pi_j-\hat{\pi}_j)^2}{k^3-k}
\end{equation}
where $\pi$ and $\hat{\pi}$ are, respectively, the target, or ``true'', ranking that is known ex-post  and predicted rankings for a given instance.\footnote{ In the following, we will use $y_i$ and $\pi_i$ interchangeably to represent the target ranking.} Figure ~(\ref{ch3-fig: timeline}) shows the time line relation between the predicted and the target rankings. We use all information available up to time $t-2$ for training data and for the independent variables. At $t-1$, we generate a new training example given new information available at time $t-1$. We apply label ranking algorithm on this updated training example and generate a ranking model which outputs the predicted rankings for period $t$. At time $t$, we measure accuracy of the predicted rankings $\hat{\pi}$ against the true one $\pi$ by applying equation ~ (\ref{ch3-eq00}).

The interpretation of the coefficient values is simple. Two orders with all the labels placed in the same position will have a Spearman correlation of $+1$. Labels placed in reverse order will produce  correlation of $-1$. Thus, the higher the value of $\rho$ the more accurate the prediction is compared to target. The loss function is given by the mean Spearman correlation values (eq. \ref{ch3-eq00}) between the predicted and target rankings, across all examples in the dataset:


\begin{equation}
\label{ch3-loss}
 \ell=\frac{\sum_{i=1}^n \rho(\pi_i,\hat{\pi}_i)}{n}
\end{equation}
An extensive survey of label ranking algorithms is given in \cite{vembu2009}.


Here we address the problem using an adaptation of naive Bayes for label ranking \citep{aiguzhinov2010} (see Appendix).

The naive Bayes label ranking algorithm relies on the similarity  among rankings. Suppose we have  artificial data for 6 quarters and rankings of 3 brokerage firms  for each of  quarter. Also assume that we identify some independent variables $x_1, x_2$ that we think are responsible for the rankings in a given quarter. Table \ref{ch3-tab01} summarizes the example.

\begin{table}
\caption{Example of Label Ranking problem}
\label{ch3-tab01}
\begin{tabularx}{\textwidth}{l*{7}{Y}}
\toprule
$t$&$x_1$&$x_2$&\multicolumn{4}{c}{Ranks}\\
\cline{4-7}
&&&A&B&C&D\\
\midrule
<<chap3-rank-ex,echo=FALSE,results='asis'>>=
options(xtable.comment = FALSE)
print(xtable(cbind(x,y)),only.contents=T,include.colnames = F,include.rownames=T,hline.after=NULL)
@
\bottomrule
\end{tabularx}
\begin{tabularx}{\textwidth}{l*{7}{Y}}
\toprule
\multicolumn{7}{l}{Panel A: conditional LR probabilty o f $x_1$} \\

<<chap3-table-cond-x1,echo=FALSE,results='asis'>>=

print(xtable(data.table(t(model$cond[x1,]),priors=model$priors)),only.contents=T,include.colnames = T,include.rownames=T,hline.after=NULL)
@
\midrule
\end{tabularx}

\begin{tabularx}{\textwidth}{l*{7}{Y}}
\multicolumn{7}{l}{Panel B: conditional LR probability of $x_2$} \\
\midrule
<<chap3-table-cond-x2,echo=FALSE,results='asis'>>=

print(xtable(data.table(t(model$cond[x2,]),priors=model$priors)),only.contents=T,include.colnames = T,include.rownames=T,hline.after=NULL)
@
\bottomrule
\end{tabularx}
\end{table}

When looking at rankings, we observe that there are instances with the equal rankings (such as quarters $\{1,3,5\}$ and quarters $\{2,6\}$). Thus, the occurrence of $\{1,2,3\}$ is more frequent (three times) than the occurrence of $\{2,3,1\}$ (twice). Moreover, the fact that the ranking of quarter 4 is similar to the one of quarter 3 intuitively increases the similarity of the latter. For the same reason, the similarity of the ranking of quarter 4, which appears only once, is also increased by the existence of similar rankings in quarters 1, 3 and 5. Based on this reasoning, we assume that the average correlation of a ranking to a set of other rankings is a measure of its similarity and can be used in substitution of the probabilities in naive Bayes for label ranking. A similar logic can be applied in defining the conditional rankings. For example, for variables $x_1$ and its value \textit{High} we have three rankings with the most frequent occurrence of rankings $\{2,3,1\}$. Thus, this ranking has a higher similarity of appearance under condition of $(x_1|High)$. A detailed formalization of the algorithm is provided in the Appendix.

We start by defining $\mathcal{S}$ as a similarity matrix between the target rankings in a training set, i.e. $\mathcal{S}_{n \times n}=\rho(y_i,y_j)$. The prior probability of a label ranking is given by:
\begin{equation}
P(y) = \frac{\sum_{i=1}^{n} \rho(y,y_i)}{n}
\end{equation}

The similarity of rankings based on the value $v$ of attribute $x$, ($x_{v}$),  or conditional probability of label rankings, is:
\begin{equation}
P(x_{v}|y)= \frac{\sum_{i: x_{i} = v}\rho(y, y_i)}{|\{i: x_{i} = v\}|}
\end{equation}


Given the prior ranking $P(y)$ and conditional probability $P(x_i|y)$, the discriminate value of $x$ can be found as follows:

\begin{equation}
DP=\frac{1}{n}\sum_{t=1}^n \min_{\forall p \neq q} \left\{\lvert P(x_p|y) - P(x_q|y) )\rvert \right\} \times \left\{\lvert P(x_p|y)-P(y)\rvert\right\}
\end{equation}



\section{State characterization variables}
\label{ch3-sec:ind.var}
Several studies try to analyze  factors that affect the performance of the analysts \citep{clement1999,brown2003,jegadeesh2004}.  However, most of these papers look at the individual characteristics of analysts such as their job experience, their affiliation,  education background, industry specializations. These variables are very important to characterize the relative performance of the analysts in general. In this paper, we focus our research on the analysis of the analysts that work in the same informational environment.

Ranking means that there are differences in opinion among the analysts.  This fact implies that there is  a dispersion in the analysts' forecasts for a given stock in a given quarter \citep{diether2002}. Thus, we can analyze  the analysts forecasts' dispersion in terms of its origin and factors that affect it; hence, assuming the same variables affect the rankings. We assume that the variation in rankings is due to the different ability of the analysts to interpret the informational environment (e.g., whether the market is bull or bear). We, thus, use variables that describe this environment.

Table (\ref{ch3-tab:ind-var}) summarizes the descriptive statistics of the variables. We select  variables based on different levels of information: broker-,  firm-, industry-specific and general economy. In each level, we want a variable to be responsible for information asymmetry and uncertainty. That is, we believe that these two domains are responsible for the differences in analysts' opinions.

\subsection{Broker-based variables}
On a broker level, we want to capture the asymmetry and uncertainty among the brokers as well as a their dispersion \citep{barron1998,barron2009,zhang2006,sheng2012}. Particularly, \cite{barron2009} point our that the reason for dispersion is either uncertainty or information asymmetry. They find that prior to earnings announcement the uncertainty component prevail, whereas around the time of earnings announcement, information asymmetry is responsible for changes in analysts' opinions. Despite  that the literature on analysts' dispersion takes the EPS as the key research component, we assume that the same forces of nature of analysts are applicable for the case of price target. Thus, we implement the same approach for the price target case.

To capture the states of the dispersion,we use the same set of variables defined in \cite{barron2009}:

\begin{eqnarray}
SE&=&(FC-\overline{FC})^2 \nonumber\\
DISP&=&\sum_{i=1}^{n} \frac{(FC_{i}-\overline{FC})^2}{(n-1)} \label{ch3-eq:disp} \\
UNCERTAINTY&=&SE+DISP \label{ch3-eq:uncert} \\
ASSYM & = & 1-\frac{SE-\frac{DISP}{n}}{\left( 1- \frac{1}{n}\right) DISP + SE } \label{ch3-eq:assym}
\end{eqnarray}
where $SE$ is the square mean error; $\overline{FC}$ is the mean price target;  and $n$ is the number of price targets in a given quarter for a given stock.

Equation (\ref{ch3-eq:disp}) calculates the dispersion among the analysts which is a variance of price targets of all analysts for a given stock. Equation (\ref{ch3-eq:uncert}) defines the Uncertainty component of the dispersion per \cite{barron2009}. As we observe, it is the sum of squared mean errors and dispersion. Equation (\ref{ch3-eq:assym}) is the proxy for information asymmetry which a function of dispersion, squared mean error, and a number of price targets.


\subsection{Firm-based variables}

To be consistent with the two paradigms that characterize the state of the analysts, we split the firm-based variables based on their influence on analysts' opinions. They are either uncertainty or the information asymmetry.

\subsubsection{Uncertainty}

The following are the set of the variables and their definitions that we think are responsible for the uncertainty component.

\paragraph{Business risk.} Business risk is associated with the uncertainty in operating results, especially, in operating earnings \citep{hill1980}. An increase in business risk entails an increase in \emph{ex-ante} volatility of the reported earnings \citep{parkash1995}.  We believe that  book-to-market ratio can serve as a proxy for the business risk measurement.
\begin{equation}
BM=\frac{EQUITY}{MKT.CAP}=\frac{Tot.assts-Tot.liab}{Stocks\times Price}
\end{equation}
where $Stocks$ is the number of stocks outstanding and $Price$ is the close stock price on last day of a quarter.

\paragraph{Financial risk.} Financial risk is responsible for the uncertainty of the future earnings. More debt implies more variability in earnings as managers would try to maximize the value of a stock using the debt; thus, having the risk of the default in the future or taking high risk investment projects. The debt-to-equity ratio is used to capture the financial risk \citep{parkash1995}. We use short-term debt from balance sheet (Notes payable) as values for debt.

\begin{equation}
DE=\frac{DEBT}{EQUITY}=\frac{ShortTermDebt}{Tot.assts-Tot.liab}
\end{equation}

\paragraph{Size.} The firm size can be used as a proxy for amount of information available for a firm. Thus, larger firm has more news coverage which reduces uncertainty. An investor is likely to find private information about larger firm more valuable than the same information about smaller firm \citep{bhushan1989}.

Size is measured as the market value (MV) of the firm as following:
\begin{equation}
MV= \log(Price \times Stocks)
\end{equation}
Consistent with the literature, we use log of market value.


\paragraph{Return variability.}
Return variability influence the uncertainty regarding future earnings \citep{diether2002,henley2003}. An increases in variability of the abnormal returns is positively correlated with the uncertainty about the earnings; thus, affecting the dispersion among the analysts. To calculate the return variability, we use method provided in \cite{sousa2008}, where stock return volatility is decompose into market and stock specific components as follow:
\begin{eqnarray}
\sigma^2_{mkt}&=&\sum_{d\in q} (R_{mkt,d}-\mu_{mkt})^2 \nonumber \\
\sigma^2_{s}&=&\sum_{d \in q} (R_{s,d}-R_{mkt,d})^2 \nonumber \\
Var (R_{s,q})&=&\sigma^2_{mkt}+\sigma^2_{s} \label{ch3-eq:ret.vol}
\end{eqnarray}
where $R_{mkt,q}$ is the market return over sample period; $\mu_{mkt}$ is the mean of daily market returns; $R_{s,q}$ is an individual stock return; $d$ is the number of trading days in period $q$.

\subsubsection{Information Asymmetry variables}
\paragraph{Accruals.}
Accruals, as a part of  earnings, is one of the variables that cause the information asymmetry between managers of a firm and investors. Studies have shown that presence of asymmetry is a necessary condition for the earnings management \citep{trueman1988,richardson2000}. To be more specific, it is the discretionary part of the accruals that causes  the information inefficiency  in the earnings management \citep{richardson2000,ahmed2005}. We calculated total accruals-to-total assets ratio defined in \cite{creamer2009}:

\begin{eqnarray}
TA=\frac{\Delta C.As - \Delta Cash - (\Delta C.Lb. - \Delta C.Lb.D) - \Delta T - D\& A_q}{(T.As. - T.As._{q-4})/2}
\end{eqnarray}
where $\Delta X=X_q-X_{q-1}$; $C.As$ -- current assets; $C.Lb$ -- current liabilities; $C.Lb.D$ -- debt in current liabilities; $T$ -- deferred taxes; $D\&A$ -- depreciation and amortization; and $T.A$ -- total assets.



\subsection{Sector-based variables}
The industry specific variables that cause the dispersion in the analysts' forecasts are connected  with the uncertainty concept. One of the variables that is suggested to capture is the variability in the industry Producer Price Index (PPI) \citep{henley2003}.


\subsection{Macroeconomics variables}
In the last set of the state variables, we want to capture the macroeconomic conditions which affect the analysts' dispersion. For example, different states of the economy are based on  different levels of ``GNP--inflation" combinations \citep{lev1993,hope2005}. When economy is booming, i.e. ``high GNP-low inflation" state, \cite{lev1993} observe the significant increase in firms' Capital Expenditures coefficient. This implies that firms start enjoy capital investment due to the low cost of capital. This state of the economy produces less uncertainty. In the ``medium GNP-high inflation" state of the economy, there is an increase in R\&D expenditures, which, from the above mentioned analysis, may spur high level of information asymmetry based on the increase R\&D activities. Finally, in the ``low GNP-high inflation" state, \cite{lev1993} observe the Doubtful Receivables coefficient is the largest implying that at this recession state many firms go bankrupt or default on the loans -- a signal of high uncertainty in the economy. All these states produce the dispersion of the analysts' forecasts.

We select the following set of the macroeconomic variables:
\begin{itemize}
\item Gross National Product (GNP);
\item Inflation rate;
\item Interest rate (90-days T-bill rate);
\item Market variability (CBOE VIX index)
\end{itemize}


\section{Data and experimental setup}
\label{ch3-sec:data}
Independent variable data obtained from ThomsonReuters Database and Datastream. The descriptive statistics presented in table (\ref{ch3-tab:ind-vvs}).

\begin{table}
\caption{Descriptive statistics of independent variable}
\ Descriptive statistics of state variables used to describe the state of the analyst.
\begin{center}
\begin{tabularx}{\linewidth}{r*{7}{Y}}
\toprule
 <<chap3-desc-ind,echo=F,results='asis'>>=
#results.final <- desc.ind[,data.to.display]

cat("Type&Variable & Stock & Median & Mean & std.dev\\\\\n")
cat('\\midrule \n')
#cat(rep('&',ncol(results.final)),'\\\\')
print(xtable(m.ind.vvs[unlist(v.type),'raw',c(1,4,3,5)],display=c('d','d','f','f','f'),digits=3),only.contents=T,include.colnames=FALSE,include.rownames=T,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(c(3,8,9),0,3,8,9,c(1,2,4,5,6,7,10,11,12)),command=c('\\midrule \n','\\multirow{3}{*}{Broker}& \n','\\multirow{5}{*}{Stock}& \n','\\multirow{1}{*}{Sector}& \n','\\multirow{4}{*}{Macro}& \n','&')))
@
\bottomrule
\end{tabularx}
\end{center}
\label{ch3-tab:ind-vvs}
\end{table}

We constructed rankings of analyst earnings forecast accuracy.\footnote{An alternative proxy to evaluate analyst predictive ability would be the correlation between analyst recommendations and future stock returns. To do so, we would have to assign standardized numerical ratings to recommendations (strong buy, buy, hold, sell, strong sell) in a similar way as it is done by Zacks Investment Research.}

We selected companies that are publicly traded in either NYSE, NASDAQ, or AMEX. The accounting data was obtained from the Thomson One/Reuters Fundamental database. We also obtained the data from I/B/E/S of all earnings per share forecasts ever made by an analyst\footnote{We use words ``analyst''  even-though the database is for brokerage houses.}  for each company at study.

We apply a number of requirements for our data. We select stocks with at least one broker has at minimum 12 quarters of experience in covering this stocks. In addition, for the computational purpose, we need at least 3 brokers per stock in each quarter.

Table ~ (\ref{ch3-table:filtered.summary}) outines the number of stocks, brokers and total forecasts in sample (Panel A) and filtered datasets (Panel B). For sample (filtered) data we report \Sexpr{eps.dt[,.N,by=Broker][,.N]} (\Sexpr{complete.dt[,.N,by=Broker][,.N]}) unique brokers covering \Sexpr{prettyNum(eps.dt[,.N,by=Stock][,.N],big.mark=' ')} (\Sexpr{prettyNum(complete.dt[,.N,by=Broker][,.N],big.mark=' ')}) stocks during \Sexpr{eps.dt[,.N,by=q.id][,.N]}  quarters from \Sexpr{gsub('[[:space:]]','',eps.dt[,head(sort(unique(q.id)),1)])} until \Sexpr{gsub('[[:space:]]','',eps.dt[,tail(sort(unique(q.id)),1)])}. For this period there were \Sexpr{prettyNum(eps.dt[,.N],big.mark=' ')} (\Sexpr{prettyNum(complete.dt[,.N],big.mark=' ')}) issued forecasts.

\begin{table}
\caption{Summary of sample and filtered data}
\ The table presents the total number of stocks, brokers and EPS forecasts for sample (Panel A) and filtered (Panel B) data.
\begin{center}
\begin{tabularx}{\linewidth}{r*{4}{Y}}
\toprule
Sector & \# stocks & \# brokers & \# forecasts \\
\multicolumn{4}{l}{\textbf{Panel A: Sample data}}\\
\midrule
<<chap3-desc-sector,echo=F,results='asis'>>=
print(xtable(stat.eps,display=c('s','d','d','d','d'),align=c('r',rep('c',ncol(stat.eps)))),only.contents=T,include.colnames=FALSE,include.rownames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(nrow(stat.eps)-1),command=c('\\midrule \n')))
@
\midrule
\end{tabularx}
\begin{tabularx}{\linewidth}{r*{4}{Y}}
\multicolumn{4}{l}{\textbf{Panel B: Filtered data}}\\
\midrule
<<chap3-desc-sector-filter,echo=F,results='asis'>>=
print(xtable(sample.stat.eps,display=c('s','d','d','d','d'),align=c('r',rep('c',ncol(stat.eps)))),only.contents=T,include.colnames=FALSE,include.rownames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(nrow(stat.eps)-1),command=c('\\midrule \n')))
@
\bottomrule
\end{tabularx}
\label{ch3-table:filtered.summary}
\end{center}
\end{table}


Table ~(\ref{ch3-table:forecasts-broker}) presents the descriptive statistics of sampled (Panel A) and filtered (Panel B) data from the ``per broker" perspecitve. Concretely, for the sample (filtered) data the total number of  ``Broker-Forecasts" observations is \Sexpr{prettyNum(per.broker[Sector=='Total',get('Observ')],big.mark=' ')} (\Sexpr{prettyNum(filter.per.broker[Sector=='Total',get('Observ')],big.mark=' ')}). Each broker, on average,  issued \Sexpr{per.broker[Sector=='Total',Forecast]} (\Sexpr{filter.per.broker[Sector=='Total',Forecast]}) forecasts per quarter, and, if we factor in stocks, the average forecasts per stock per quarters becomes \Sexpr{per.broker[Sector=='Total',get('Forecast/broker')]} (\Sexpr{filter.per.broker[Sector=='Total',get('Forecast/broker')]}). Finally, on average,  a broker followed a stocks for \Sexpr{per.broker[Sector=='Total',get('Follow time,q')]} (\Sexpr{filter.per.broker[Sector=='Total',get('Follow time,q')]}) quarters.

\begin{table}
\caption{Descpriptive statistics of forecasts per broker}
\ The table presents the descriptive statistics  for sample (Panel A) and filtered (Panel B) data. Namely, the table shows the total number of Broker-Forecast observations, the average number of forecast per quarter, the average number of following stocks per broker, the average number of forecasts per stock per broker, and, finally, the average number of quarters a broker follows a stock.
\begin{center}
%\begin{tabular}{rcccc}
\begin{tabularx}{\linewidth}{r*{6}{Y}}
 \toprule
 &Obsrv & Frcst/q & Stocks & Frcst/stock & follow time, q \\
 \multicolumn{6}{l}{\textbf{Panel A: Sample data}}\\
  \midrule
<<chap3-per-brok,echo=F,results='asis'>>=
print(xtable(per.broker,display=c('s','d','d','f','f','f','f')),only.contents=T,include.colnames=FALSE,include.rownames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(nrow(per.broker)-1),command=c('\\midrule \n')))
@
\midrule
\end{tabularx}
\begin{tabularx}{\linewidth}{r*{6}{Y}}
\multicolumn{6}{l}{\textbf{Panel B: Filtered data}}\\
%  \cline{2-5}
% & Forecasts & Brokers & Forecast/stock & follow time, q \\
 \midrule
<<chap3-per-brok-filter,echo=F,results='asis'>>=
print(xtable(filter.per.broker,display=c('s','d','d','f','f','f','f')),only.contents=T,include.colnames=FALSE,include.rownames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(nrow(per.stock)-1),command=c('\\midrule \n')))
@
\bottomrule
\end{tabularx}
\label{ch3-table:forecasts-broker}
\end{center}
\end{table}

The similar descriptive analys but from ``per stock" perspective presented in table ~(\ref{ch3-table:forecasts-stock}). Namely, for the sample (filtered) data the total number of  ``Stock-Forecasts" observations is \Sexpr{prettyNum(per.stock[Sector=='Total',get('Observ')],big.mark=' ')} (\Sexpr{prettyNum(filter.per.stock[Sector=='Total',get('Observ')],big.mark=' ')}). Each stock, on average, receives \Sexpr{per.stock[Sector=='Total',Forecast]} (\Sexpr{filter.per.stock[Sector=='Total',Forecast]}) forecasts per quarter.  The average forecasts per broker per quarters becomes \Sexpr{per.stock[Sector=='Total',get('Forecast/stock')]} (\Sexpr{filter.per.stock[Sector=='Total',get('Forecast/stock')]}). Finally, on average,  a stocks is followed by a broker for \Sexpr{per.stock[Sector=='Total',get('Follow time,q')]} (\Sexpr{filter.per.stock[Sector=='Total',get('Follow time,q')]}) quarters.

\begin{table}
\caption{Descpriptive statistics of forecasts per stock}
\ The table presents the descriptive statistics per stock for sample (Panel A) and filtered (Panel B) data. Namely, the table shows the total number os Stock-Forecast observations,  the average number of forecast per quarter per stock, the average number of following brokers per stock, the average number of forecasts per broker per stock, and, finally, the average number of quarters a stock being followed by a broker.
\begin{center}
%\begin{tabular}{rcccc}
\begin{tabularx}{\linewidth}{r*{6}{Y}}
 \toprule
 &Obsrv & Frcst/q & Brokers & Frcst/broker & follow time, q \\
 \multicolumn{5}{l}{\textbf{Panel A: Sample data}}\\
  \midrule
<<chap3-per-stock,echo=F,results='asis'>>=
print(xtable(per.stock,display=c('s','d','d','f','f','f','f')),only.contents=T,include.colnames=FALSE,include.rownames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(nrow(per.broker)-1),command=c('\\midrule \n')))
@
\midrule
\end{tabularx}
\begin{tabularx}{\linewidth}{r*{6}{Y}}
\multicolumn{6}{l}{\textbf{Panel B: Filtered data}}\\
%  \cline{2-5}
% & Forecasts & Brokers & Forecast/broker & follow time, q \\
 \midrule
<<chap3-per-stock-filter,echo=F,results='asis'>>=
print(xtable(filter.per.stock,display=c('s','d','d','f','f','f','f')),only.contents=T,include.colnames=FALSE,include.rownames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(nrow(per.stock)-1),command=c('\\midrule \n')))
@
\bottomrule
\end{tabularx}
\label{ch3-table:forecasts-stock}
\end{center}
\end{table}

Figures ~(\ref{ch3-fig:tot} --- \ref{ch3-fig:mean-stock}) depict some per quarter dynamics.


\begin{figure}
<<chap3-fig-num,echo=FALSE, include=TRUE,results='hide',fig.width=10.7,fig.height=8.3>>=
plot.data <- num.f.dt[,sum(N),by=.(q.id,data.type)][,logN:=c(0,diff(log(V1))),by=data.type]
ggplot(plot.data,aes(x=as.Date(q.id),y=V1,color=data.type))+theme_bw()+xlab('Quarters')+ylab('Forecasts,log10 scaling')+theme(plot.title = element_text(colour = "Black"),legend.position='top',legend.title=element_blank(),strip.text=element_text(size=20),text=element_text(size=20,family='Times'))+ggtitle('Total number of EPS forecasts')+geom_line()+scale_y_log10()
@
\caption{Total number of EPS forecasts.}
\ The plot shows the log of total number of forecasts per quarter
\label{ch3-fig:tot}
\end{figure}

\begin{figure}
<<chap3-fig-mean-f,echo=FALSE, include=TRUE,results='hide',fig.width=10.7,fig.height=8.3>>=

plot.data <- rbind(num.f.dt[,sum(N),by=.(q.id,Stock,data.type)][,mean(V1),by=.(q.id,data.type)][,perspective:='per stock'],
num.f.dt[,sum(N),by=.(q.id,Broker,data.type)][,mean(V1),by=.(q.id,data.type)][,perspective:='per broker'])

ggplot(plot.data,aes(x=as.Date(q.id),y=V1,color=data.type))+theme_bw()+geom_smooth(method='loess',se=F)+xlab('Quarters')+ylab('Forecast')+theme(plot.title = element_text(colour = "Black"),legend.position='top',legend.title=element_blank(),strip.text=element_text(size=20),text=element_text(size=20,family='Times'))+geom_line()+ggtitle('Average EPS forecast per quarter')+facet_wrap(~perspective,scale='free_y')
@
\caption{Average number of EPS forecasts per broker (stock)}
\ The plot depicts the average number of EPS forecasts per quarter for sample and filtered datasets.
\label{ch3-fig:mean-forecast}
\end{figure}

\begin{figure}
<<chap3-fig-tot-stocks,echo=FALSE, include=TRUE,results='hide',fig.width=10.7,fig.height=8.3>>=

## Calculates number of Brokers per stock and number of stocks per broker
plot.data <- rbind(num.f.dt[,.N,by=.(q.id,Stock,data.type)][,mean(N),by=.(q.id,data.type)][,perspective:='brokers/stock'],
num.f.dt[,.N,by=.(q.id,Broker,data.type)][,mean(N),by=.(q.id,data.type)][,perspective:='stocks/broker'])

ggplot(plot.data,aes(x=as.Date(q.id),y=V1,color=data.type))+theme_bw()+geom_smooth(method='loess',se=F)+xlab('Quarters')+theme(plot.title = element_text(colour = "Black"),legend.position='top',legend.title=element_blank(),strip.text=element_text(size=20),text=element_text(size=20,family='Times'))+geom_line()+ggtitle('Average number of brokers/stock and of stocks/broker')+facet_wrap(~perspective,scale='free_y')+ylab('Count')#+geom_line(stat = "hline", yintercept = "mean")
@
\caption{Average number of brokers (stocks) per stock (broker)}
\ The figure shows the average number of brokers per stock and of stocks per broker for sample and filtered datasets.
\label{ch3-fig:mean-stock}
\end{figure}




\subsection{Target  rankings of analysts}
Prior to address the problem of predicting the rankings of the analysts, it is important to create the target rankings $y_i$, which the approach described here will try to predict. They are the ``true'' rankings in the sense that they are calculated ex-post based on one of the analysts' performance evaluation models \citep{clement1999,brown2001,creamer2009}. In this paper, the target rankings of analysts are based on the Proportional  Mean Absolute Forecast Error (\textit{PMAFE}) that measures the forecast accuracy \citep{brown2001}. If we define the  Forecast Error  (FE) as an absolute value of the difference between I/B/E/S actual quarter earnings of a stock and the latest forecast made by an analyst for that quarter:
\begin{equation}
\mathrm{FE_{q,a,s}}=|\mathrm{ActEPS_{q,s}}-\mathrm{EPS_{q,a,s}}|
\end{equation}
where $q$ is a quarter, $a$ and $s$ are the analysts and stocks indexes, then consensus forecast error is given by:
\begin{equation}
\mathrm{\overline{FE_{q,s}}}=\frac{1}{n}\sum_{a=1}^n \mathrm{FE_{q,a,s}}
\end{equation}
where $n$ is the number of analysts in a given quarter

PMAFE is given as:\footnote{The rankings that are commonly used by $\mathrm{FE}$ and $\mathrm{PMAFE}$ are the same. The latter is more common in the literature where OLS methods in regression analyses require normalization of the data.}
\begin{equation}
\mathrm{PMAFE_{q,a,s}}=1+\frac{\mathrm{FE_{q,a,s}}-\mathrm{\overline{FE_{q,s}}}}{\mathrm{\overline{FE_{q,s}}}}=\frac{\mathrm{FE_{q,a,s}}}{\mathrm{\overline{FE_{q,s}}}}
\end{equation}
To rank the analysts based on their PMAFE, we scaled these values by adding 1 so that those analysts who made an absolute match of EPS forecast with actual values (PMAFE=0) would receive a higher rank. In case the analysts does not issue a forecast in the subsequent quarters, we do not roll over her previous forecasts.

An analyst that follows one stock, does not necessarily issue forecast every quarter. Therefore, the question is how to evaluate a predicted ranking in this case. For instance, when the ranking \{John, Brown, Smith\} is predicted and then Brown does not make a forecast during the corresponding quarter. In this case, we assume that the investor will simply ignore the forecast. Therefore, when evaluating the accuracy of a predicted ranking, we remove all analysts that have not made EPS forecasts during the corresponding quarter


We perform a simple analysis of the target rankings. Specifically, we compare the composition of top $n$ and last $n$ brokers on quarter-to-quarter basis. Table (\ref{ch3-rank-stat}) shows the composition of top and bottom rankings at period $t$ compared to top and bottom rankings at period $t+1$.  We find that at period $t$, the top $n$ rankings consists of both: the  brokers that stayed in top $n$ rankings of period $t+1$  and the brokers that were in last $n$ rankings at $t+1$. That is, period $t$ top rankings have, on average, an equal proportion of the brokers that stayed in the top rankings and the ones that moved from the last rankings to top rankings.

The same analysis of the last $n$ rankings reveal somewhat different behavior. We find that period $t$ bottom rankings,  on average, consists mostly from the brokers that were in the last rankings at period $t+1$ and less from the brokers from top ranks at $t+1$. That is, top broker of period $t+1$, on average, do not move to the bottom ranks at period $t$. The outcome of this analysis reveal that there is a strong consistency of the brokers that are in the top ranks. These brokers tend to stay on top from quarter to quarter. The bottom ranks are not as consistent as the top ones as these brokers can move to the top ranks or stay in the last positions.

\begin{table}
  \caption{Analysts' accuracy consistency}
\label{ch3-rank-stat}
\ The contingency table shows changes in analysts'  \textit{top}, \textit{middle}, \textit{bottom} ranking bins.
\begin{tabularx}{\linewidth}{r*{6}{Y}}
    \toprule
&&$top$&$middle$&$bottom$&$Sum$\\
\midrule
\multirow{10}{*}{$t$}&&\multicolumn{4}{c}{$t+1$} \\
%&&$top$&$middle$&$bottom$&Sum\\
<<desc-rank-eps-t1,echo=F,results='asis'>>=
tab.r <- acast(rbind(melt(eps.cont.tab[,,'t']),data.table(melt(apply(eps.cont.tab,c(1,3),sum)))[Var2=='t']),Var1~Var2,value.var='value')*100
rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r,hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,sanitize.text.function = function(x) x)
tab.r <- acast(rbind(melt(eps.cont.tab[,,'t+4']),data.table(melt(apply(eps.cont.tab,c(1,3),sum)))[Var2=='t']),Var1~Var2,value.var='value')*100
rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r,hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,add.to.row=list(pos=list(0),command=c('&&\\multicolumn{4}{c}{$t+4$}\\\\ \n')),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}



\section{Experimental setup}
\label{ch3-sec:exp_setup}
Given that the data are ordered in time, we estimate the accuracy of the methods using a growing window approach. When predicting the ranking for quarter $q$, the training set consists of the data for all quarters $i \in 1 \ldots q-1$. We consider timing in rankings; that is, the algorithm gives more weight to the most recent rankings and less weight to the old ones.

To test whether our approach is identifying meaningful patterns in the data, we compare it with simple baseline methods. The first baseline method is based on the mean rank of each label over all training examples \citep{brazdil2009}.

\begin{equation}
\label{ch3-default.rank}
\hat{\pi}^{-1}_{j} = \frac{\sum_{i=1}^n \pi^{-1}_{i,j}}{n}
\end{equation}
where $\pi^{-1}_{i,j}$ is the rank of label $\lambda_j$ on dataset $i$. The final ranking is obtained by ordering the mean ranks and assigning them to the labels accordingly. This ranking is usually called the \emph{default ranking}, in parallel to the default class in supervised classification \citep{mitchell1997}.

The second baseline method that we compare our predicted rankings is to simply  take  the rankings from the previous quarter. That it, use rankings from past quarter $\pi_{q-1}$ as prediction of the rankings for  the current quarter $\hat{\pi}_q$:

\begin{equation}
\label{ch3-naive:ranking}
\hat{\pi}_q=\pi_{q-1}
\end{equation}
We call this baseline method the \emph{naive ranking}. The accuracy of the methods is measured using Spearman's rank correlation coefficient (Eq.~\ref{ch3-eq00}) as is done for the naive Bayes ranking method.

The independent variables are fed into the predicting algorithm with three different methods of aggregation. As we have mentioned above, we want to capture the state of the world in which the analysts operate. For this reason, it is necessary to take into account the dynamics of independent variables from one time period to another. We call this an aggregation of the independent variables and we propose the following methods:
\begin{itemize}
\item \raw: no dynamics in the state of the  variables, i.e. independent variables used as they are --- $x_t$;
\item  \diff: first-differencing  of the variables,i.e., $x_{\Delta{t}}=x_t-x_{t-1}$;
\item  \random: using random part of the time series decomposition of the independent variables for the previous 8 quarters: $x_{\Delta{t}}=T(t)+S(t)+\epsilon (t)$, where $T(t)$- trend, $S(t)$ - seasonal part and $\epsilon (t)$ - the random part of time series;
\item  \rollsd: rolling 8 quarters standard deviation of the independent variables;
\end{itemize}

Obviously, each of these methods produce its own predicted rankings; that is why, we will have four sets of evaluation values in addition to the two baselines.

 %We also perform a significance test using Student p-values for pairs of $\rho$ obtained using Eq.(\ref{ch3-eq00}). The first pair to test the significance in differences is $(\rho_{NBr}; \rho_{default})$ and second  is  $(\rho_{NBr}; \rho_{naive})$.




\section{Results}
\label{ch3-sec:results}

%

%\subsection{Predictive ranking accuracy of naive Bayes for  label ranking}
We start by analyzing the accuracy of the naive Bayes for ranking  $NBLR(t)$ on  the datasets tested here and discuss if it possible to predict the rankings

Applying equation of a loss function (\ref{ch3-loss}), the average ranking accuracy of  predicted rankings, measured as a correlation between predicted rankings (\raw{}, \diff{}, \random{}, \rollsd{} is reported in Table (\ref{ch3-stat:acc}). We observe that, on average, the naive Bayes for label ranking consistently outperforms both of the baselines. This implies that the algorithm is able to identify the pattern in the data that produce the positive outcomes in the prediction. The result also suggests that the \naive{} prediction is not the best guess of the rankings;  moreover,  the state variables are responsible for the relative performance of the brokers.

Table (\ref{ch3-table:dp-ab}) shows the results of identifying the discriminative power of the variables.

\begin{table}
\caption{Discriminate power of the variables}
\label{ch3-table:dp-ab}
\begin{tabularx}{\linewidth}{r*{5}{Y}}
\toprule
 \multicolumn{5}{l}{\textbf{Panel A: \raw}}\\
 Type&Variable& median & mean & st.dev\\
  \midrule
<<chap3-dp-raw,echo=F,results='asis'>>=

print(xtable(res.dp[,,'raw']),display=c('s',rep('f',4)),only.contents=T,include.colnames=FALSE,include.rownames=T,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(c(4,10,11),0,4,10,11,c(1,2,5,6,7,8,12,13,14),c(3,9,15)),command=c('\\midrule \n','\\multirow{3}{*}{Broker}& \n','\\multirow{5}{*}{Stock}& \n','\\multirow{1}{*}{Sector}& \n','\\multirow{4}{*}{Macro}& \n','&','\\cline{2-5}& \n')))
@
\midrule
\end{tabularx}
\begin{tabularx}{\linewidth}{r*{5}{Y}}
 \multicolumn{5}{l}{\textbf{Panel B: \diff}}\\
 Type&Variable& median & mean & st.dev\\
  \midrule
<<chap3-dp-diff,echo=F,results='asis'>>=

print(xtable(res.dp[,,'diff']),display=c('s',rep('f',4)),only.contents=T,include.colnames=FALSE,include.rownames=T,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(c(4,10,11),0,4,10,11,c(1,2,5,6,7,8,12,13,14),c(3,9,15)),command=c('\\midrule \n','\\multirow{3}{*}{Broker}& \n','\\multirow{5}{*}{Stock}& \n','\\multirow{1}{*}{Sector}& \n','\\multirow{4}{*}{Macro}& \n','&','\\cline{2-5}& \n')))
@
\bottomrule
\end{tabularx}
\end{table}

\begin{table}
\caption{Discriminate power of the variables (continuted)}
\label{ch3-table:dp:cd}
\begin{tabularx}{\linewidth}{r*{5}{Y}}
\toprule
 \multicolumn{5}{l}{\textbf{Panel C: \rollsd}}\\
 Type&Variable& median & mean & st.dev\\
  \midrule
<<chap3-dp-roll,echo=F,results='asis'>>=

print(xtable(res.dp[,,'roll.sd']),display=c('s',rep('f',4)),only.contents=T,include.colnames=FALSE,include.rownames=T,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(c(4,10,11),0,4,10,11,c(1,2,5,6,7,8,12,13,14),c(3,9,15)),command=c('\\midrule \n','\\multirow{3}{*}{Broker}& \n','\\multirow{5}{*}{Stock}& \n','\\multirow{1}{*}{Sector}& \n','\\multirow{4}{*}{Macro}& \n','&','\\cline{2-5}& \n')))
@
\midrule
\end{tabularx}
\begin{tabularx}{\linewidth}{r*{5}{Y}}
 \multicolumn{5}{l}{\textbf{Panel D: \random}}\\
 Type&Variable& median & mean & st.dev\\
  \midrule
<<chap3-dp-ran,echo=F,results='asis'>>=

print(xtable(res.dp[,,'random']),display=c('s',rep('f',4)),only.contents=T,include.colnames=FALSE,include.rownames=T,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(c(4,10,11),0,4,10,11,c(1,2,5,6,7,8,12,13,14),c(3,9,15)),command=c('\\midrule \n','\\multirow{3}{*}{Broker}& \n','\\multirow{5}{*}{Stock}& \n','\\multirow{1}{*}{Sector}& \n','\\multirow{4}{*}{Macro}& \n','&','\\cline{2-5}& \n')))
@
\bottomrule
\end{tabularx}
\end{table}

The detailed analysis of the table (\ref{ch3-stat:acc}) shows that the \rollsd{} method has the highest average accuracy compared to other methods. This means that the dynamics of the state of the world for the previous two year can be responsible for the rankings of the brokers. Table (\ref{ch3-stat:acc:time})  and figure (\ref{ch3-fig: acc.time}) present the average annual accuracy for each of the methods on the annual basis. We observe the best performance of \rollsd{} method for the all period except for 2009. We suggest that this behavior has to do with the crisis of 2008. The downward trend of the accuracy is attributed to the ``growing window'' approach in treating the historical rankings, i.e., for training the algorithm we use all available rankings since the beginning of the dataset. An alternative will be to use the ``sliding window'' approach where old rankings are discarded from the model based on the specified period of time (window).

\begin{figure}
<<chap3-fig-dp,echo=FALSE, include=TRUE,results='hide',fig.width=10.7,fig.height=8.3>>=
ggplot(na.omit(metric.vvs)[,mean(metric),by=.(vvs,method)],aes(x=vvs,y=V1))+facet_grid(method~.)+geom_bar(stat='identity')+theme_bw()+ggtitle('Average discriminative power across variables')+theme(plot.title = element_text(colour = "Black"),legend.position='top',legend.title=element_blank(),strip.text=element_text(size=20),strip.text.y = element_text(angle = 0),text=element_text(size=20,family='Times'),axis.text.x=element_text(angle=45,vjust=1,hjust=1))
@
\caption{The average discriminative power.}
\ The plot depicts the average discriminative power of variables conditonal on different aggregation settings: \diff{} is the first-differece, \random{} is the random part of time-series decomposition, \raw{} is an unaltered levels, and \rollsd{} is the rolling 8 quarters standard deviation.
\label{ch3-fig:mean-dp}
\end{figure}


\begin{figure}
<<chap3-fig-dp-q-id,echo=FALSE, include=TRUE,results='hide',fig.width=10.7,fig.height=8.3,warning=FALSE>>=
plot.data <- na.omit(metric.vvs)[,round(mean(metric),3),by=.(vvs.type,method,q.id)]
ggplot(plot.data,aes(x=as.Date(q.id),y=log(V1),fill=vvs.type))+geom_bar(stat='identity',position='stack')+theme_bw()+facet_grid(method~.,scales='free_y')+ggtitle('Average per quarter DP across stocks')+ylab('Mean DP')+xlab('Quarters')+theme(plot.title = element_text(colour = "Black"),legend.position='top',legend.title=element_blank(),strip.text=element_text(size=20),strip.text.y = element_text(angle = 0),text=element_text(size=20,family='Times'))
@
\caption{Log of avarage discriminative power}
\ The plot shows log of the average discriminative power of type of variables across quarters. Different aggregation methods are: \diff{} is the first-differece, \random{} is the random part of time-series decomposition, \raw{} is unaltered levels, and \rollsd{} is the rolling 8 quarters standard deviation.
\label{ch3-fig:time-dp}
\end{figure}



\section{Conclusion}
\label{ch3-sec:conclusion}
Some institutions, such as StarMine, rank financial analysts based on their accuracy and investment value performance. These rankings are published and are relevant: stocks favored by top-ranked analysts will probably receive more attention from investors. Therefore, there is a growing interest in understanding the relative performance of analysts. Typical approaches are based on individual characteristics of those analysts or past analyst forecasting accuracy. Here, we follow an alternative approach that links the general behavior of rankings of analysts to variables such as consensus statistics and company characteristics.

The proposed method of predicting the rankings produced  results that outperformed simple  baselines. In addition, the algorithm identified that deviations of the independent variables are responsible in explaining the rankings of the brokers. The positive results of this study can attribute for the future research in the area of finding the relation between the state of the world and the performance of the brokers as well as  in the area of developing a trading strategy based on the predicted rankings.
