
<<include=FALSE>>=
library(knitr)
opts_chunk$set(concordance=TRUE)
options(digits = 2)
@
%<<set-parent, echo=FALSE, cache=FALSE>>=
%set_parent('~/Dropbox/workspace/Projects/Thesis/thesis.Rnw')
%@
<<chapt-4-load.data,echo=F,warning=FALSE,message=FALSE>>=
strategies <- c('true','recent','all-time')
con <- 'CONS'
tp <- 'TP'
eps <- 'EPS'
setwd('~/Dropbox/workspace/Projects/Black-Litterman/')
library(reshape2)
library(descr)
library(data.table)
library(ggplot2)
library(stringr)
library(zoo)
library(xtable)
library(abind)
library(PerformanceAnalytics)
library(rapport)
load('cache/q.data.RData')
load('cache/final.bl.RData')
load('cache/pt.accu.RData')
load('cache/eps.accu.RData')
load('cache/pt.dp.RData')
load('cache/eps.dp.RData')
load('cache/vvs.names.RData')
load('cache/nr.views.RData')
load('cache/pt.rank.views.RData')
#load('cache/eps.rank.views.RData')
load('cache/cont.tab.RData')
load('~/Dropbox/workspace/Projects/BL-strategies/cache/market.set.RData')
#load('~/Dropbox/workspace/Projects/EPS/cache/metric.vvs.RData')
source('lib/aux.functions.R')
source('lib/ranking.scripts.R')
###Statistics for views:
###non rank base data



q.data <- na.omit(q.data)

stocks.m <- setkey(data.table(Stock.m=sort(market.set[,unique(Stock)])),Stock.m)

quarters <- setnames(unique(market.set[,.(Quarters)]),'q.id')[,q.id:=as.yearqtr(q.id)]
load('~/Dropbox/workspace/Projects/EPS/cache/complete.dt.RData')

complete.dt <- na.omit(setkey(complete.dt,q.id)[quarters])

stocks <- setkey(data.table(Stock=sort(intersect(stocks.m$Stock.m,setkey(q.data,q.id)[quarters]$Stock))),Stock)



trunk.percent <- 0.05
q.data <- na.omit(q.data[,trunk.view:=truncate.f(b.view,trunk.percent)][,year:=format(q.id,'%Y')])


core.dt <- q.data[,core.b:=.N>=12,by=list(Stock,Broker)][(core.b)][,true:=rank(score),by=list(q.id,Stock)][,core.s:=.N>=3,by=list(q.id,Stock)][(core.s)][,core.q:=length(unique(q.id))>=8,by=.(Stock)][(core.q)]
#broker.vvs <- acast(melt(unique(core.dt[,broker.vvs.f(PT,priceAdj),by=list(q.id,Stock)],by=c('q.id','Stock')),id.vars = c('q.id','Stock'),measure.vars = c('uncertainty','assym','dispersion')),q.id~Stock~variable)
#stats.q.data <- summary.stat(q.data[!is.na(trunk.view),])

brok.full.stat.pt <- rbind(setkey(core.dt[,.N,by=.(Stock,q.id,year)][,list(min=min(N),mean=mean(N),median=as.numeric(median(N)),max=max(N),st.dev=sd(N)),by=.(year)],year),setnames(cbind('Total',(core.dt)[,.N,by=.(Stock,q.id,year)][,list(min=min(N),mean=mean(N),median=as.numeric(median(N)),max=max(N),st.dev=sd(N))]),1,'year'))

brok.full.stat.eps <- rbind(setkey(complete.dt[,.N,by=.(Stock,q.id,year)][,list(min=min(N),mean=mean(N),median=as.numeric(median(N)),max=max(N),st.dev=sd(N)),by=.(year)],year),setnames(cbind('Total',complete.dt[,.N,by=.(Stock,q.id,year)][,list(min=min(N),mean=mean(N),median=as.numeric(median(N)),max=max(N),st.dev=sd(N))]),1,'year'))

for(j in as.integer(seq_len(ncol(eps.dp))))
{
        set(eps.dp,i=which(is.infinite(eps.dp[[j]])),j,NA)
}

vvs.paper.name <- c('uncert','assym','disp','btm','size','dte','accr','s.ret','sec.ret','gnp','infl','vix.ret','t.bill')

for (i in 1:13)
  {set(eps.dp,i=which(eps.dp[[2L]]==vvs.names[i]),2L,vvs.paper.name[i])
}

eps.dp$vvs <- factor(eps.dp$vvs,levels=vvs.paper.name)

setkey(eps.dp,Stock)
share.vvs <- acast(na.omit(eps.dp)[round(metric)>0][,sum(metric),by=.(vvs,method)][,share:=V1/sum(V1)*100,by=.(method)],vvs~method,value.var='share')

methods<-c('last','diff','random','roll.sd')
baselines<-c('true','naive','default')

for(a in 1:3){
set(final.bl,i=which(final.bl[[3L]]==baselines[a]),3L,value=strategies[a])}

method.paper <- c('static',methods[2:4])
#final.bl[,Method:=as.character(Method)]
for(i in 1:length(methods))
{set(final.bl,i=which(final.bl[[3L]]==methods[i]),3L,method.paper[i])}

for(i in 1:length(c(baselines,methods)))
{set(pt.accu,i=which(pt.accu[[3L]]==c(baselines,methods)[i]),3L,c(strategies,method.paper)[i])}
for(i in 1:length(c(baselines,methods)))
{set(eps.accu,i=which(eps.accu[[3L]]==c(baselines,methods)[i]),3L,c(strategies,method.paper)[i])}

pt.accu$variable <- factor(pt.accu$variable,levels=c(strategies,method.paper))
eps.accu$variable <- factor(eps.accu$variable,levels=c(strategies,method.paper))


#### WORKING CODE: COMMETED TO SAVE TIME ####
####
# load('cache/ranked.pt.dt.RData')
# n <- 3
# n.b <- 3
# setnames(ranked.pt.dt,'rank','true')
# setnames(ranked.eps.dt,'rank','true')
#
# pt.cont.tab <- abind(lapply(c(1,4),function(i) {cont.tab.f(ranked.pt.dt,i,n.b)}),along=4,new.names=list(NULL,NULL,NULL,c('t','t+4')))
#
# eps.cont.tab <- abind(lapply(c(1,4),function(i) {cont.tab.f(ranked.eps.dt,i,n.b)}),along=4,new.names=list(NULL,NULL,NULL,c('t','t+4')))
# save(pt.cont.tab,eps.cont.tab,file='./cache/cont.tab.RData')
# ### present ranking accuracy
###
eps.rank <- rbind(dcast.data.table(eps.accu[,':='(year=format(q.id,'%Y'))],year~variable,value.var='value',fun.aggregate=mean),dcast.data.table(data.table(year='Total',eps.accu[,mean(value),by=variable]),year~variable,value.var='V1'))


eps.rank.results <- cbind(eps.rank[,.(year,true)],eps.rank[,lapply(.SD,function(i){ifelse(recent<i&`all-time`<i,paste0('\\textbf{',round(i,4),'}'),round(i,4)) }),.SDcols=c(strategies,method.paper)])

pt.rank <- rbind(dcast.data.table(pt.accu[,':='(year=format(q.id,'%Y'))],year~variable,value.var='value',fun.aggregate=mean),dcast.data.table(data.table(year='Total',pt.accu[,mean(value),by=variable]),year~variable,value.var='V1'))


pt.rank.results <- cbind(pt.rank[,.(year,true)],pt.rank[,lapply(.SD,function(i){ifelse(recent<i&`all-time`<i,paste0('\\textbf{',round(i,4),'}'),round(i,4)) }),.SDcols=c(strategies,method.paper)])

final.bl$Method <- factor(final.bl$Method,levels=c(strategies,method.paper,'Market'))

#final.bl$Views <- factor(final.bl$Views,levels=unique(final.bl$Views)[c(1,2)])

final.bl <- final.bl[,ann.ret:=ann.ret*100][,ann.st:=ann.sd*100]
bl.results <- acast(unique(melt(data = final.bl,id.vars = c('Views','Method','type'),measure.vars  = c('ann.ret','ann.st','ann.sr','meanViews','Ave.TO')),by=c('Views','Method','variable','type')),Method~type~variable~Views,value.var = 'value')

quarters <- unique(final.bl[,Quarters])
periods.id <- c(paste(gsub('[[:space:]]','',rollapplyr(as.character(quarters),20,first,by=4)),gsub('[[:space:]]','',rollapplyr(as.character(quarters),20,last,by=4)),sep='/'),'All period')

periods <- rbind(final.bl[,data.table(rollapplyr(port.ret,20,roll.ret.f,by=4,partial=F)),by=.(Views,type,Method)][,strat:='yes'],final.bl[,data.table(rollapplyr(ns.port.ret,20,roll.ret.f,by=4,partial=F)),by=.(Views,type,Method)][,strat:='no'],final.bl[,data.table(roll.ret.f(port.ret)),by=.(Views,type,Method)][,strat:='yes'],final.bl[,data.table(roll.ret.f(ns.port.ret)),by=.(Views,type,Method)][,strat:='no'])[,period:=periods.id,by=.(Views,type,Method,strat)][,sr:=ann.ret/ann.sd]


periods.array <- acast(unique(melt(periods,id.vars = c('Views','type','Method','period','strat')),by=c('Views','type','Method','period','strat','variable')),period~type~Method~strat~variable~Views,value.var = 'value')

start.year <- format(as.Date(final.bl[,head(Quarters,1)]),'%Y')
end.year <- format(as.Date(final.bl[,tail(Quarters,1)]),'%Y')
####Descr stat of TP/P-1

stat.nr <- rbind(na.omit(nr.views)[,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(year,Method)],setnames(cbind('Total',na.omit(nr.views)[,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(Method)]),1,'year'))[,Strategy:='CONS']

stat.pt.view <- rbind(pt.rank.views[View!=0,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(year,Method)],setnames(cbind('Total',pt.rank.views[View!=0,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(Method)]),1,'year'))[,Strategy:='PT']

#stat.eps.view <- rbind(eps.rank.views[View!=0,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(year,Method)],setnames(cbind('Total',eps.rank.views[View!=0,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(Method)]),1,'year'))[,Strategy:='EPS']

stat.full <- rbind(stat.nr,stat.pt.view)


test <- melt(stat.full,id.vars = c('year','Method','Strategy'))
test.a <- acast(test,year~Method~Strategy~variable,value.var = 'value')

pvalue.f <- function(dt,j)
{
  #dt1 <- setkey(dt[Method==j],Stock,q.id,year)
  #dt2 <-setkey(dt[variable!=j],Stock,q.id,year)
  #na.omit(dt2[dt1])[,as.list(htest.short(t.test(value,i.value,alternative='t',paired=T))),by=.(variable)][,sig:=ifelse(p<1/100,'***',ifelse(p<5/100,'**',ifelse(p<1/10,'*','(---)')))]

  dt1 <- setkey(dt[Method==j],Quarters,Views)
  dt2 <-setkey(dt[Method!=j],Quarters,Views)

  na.omit(dt2[dt1])[,as.list(htest.short(t.test(ann.cum.ret,i.ann.cum.ret,alternative='t',paired=T))),by=.(Method,Views)]
}
cum.ret <- final.bl[,.(Quarters,Views,Method,ann.port.ret)][,ann.cum.ret:=rollapplyr(ann.port.ret,seq_len(length(ann.port.ret)),function(i){prod(1+i)-1}),by=.(Views,Method)]

cum.ret.pvalues <- rbindlist(lapply(method.paper,function(j){pvalue.f(cum.ret,j)[,method:=j]}))

t.stat.last <- abind(acast(cum.ret.pvalues[Views=='TP'],Method~method,value.var='t'),acast(cum.ret.pvalues[Views=='TP'],Method~method,value.var='p'),along=3)[,method.paper,]


@


\section{Introduction}
\label{ch4-sec:introduction}


Rankings of financial analysts is not new in finance. Many agencies develop their procedures to evaluate analysts based on their performance either in forecasting or stock recommendations. Some institutions even hold a ``Red Carpet" event to recognize the top analysts. On one hand, for market participants, the rankings may signal who is the best analysts. On the other hand, studies have shown that following the best analysts' recommendations of buy-sell stocks have statistically insignificant benefits.

In this paper we have an objective to show that rankings can serve as inputs for trading; that is, they can be a direct input for strategy. We base our research on the main assumption that analysts at the top ranks are the best analyst and they are worth to be followed. Naturally, instead of relying on personal expertise in selecting the expected returns, it is best to refer to the specialist in the field, namely, the financial analysts. Using the analysts' price target information we  create a vector of expected returns and use it as a starting point for appropriate trading strategy.

Given the objective of the paper, we have to solve two problems. First, we need to predict the rankings of the analyst and, second, translate these rankings into an operational input for the trading strategy.

For the first problem, we take advantage of the algorithm used for prediction of rankings developed in \cite{aiguzhinov2010} and adapt it for the case of analysts' rankings. In short, this algorithm is based on the Bayesian probability and the similarities between the rankings.
The solution for the second problem relies on the Black-Litterman (BL) model~\citep{black1992}. We are particularly confident in this choice of tools given that the BL model and ranking algorithm are both based on the Bayesian framework. Given the results form \cite{aiguzhinov2015a}, we base our rankings on analysts' target prices as it has been shown that strategies based on these rankings are the ones that yield the highest cumulative annualized return.



%The paper is organized as follows: \vref{ch4-sec:ranking} provides motivation on use of rankings; \vref{ch4-sec:trading} outlines the trading strategy; \vref{ch4-sec:rankings} explains the methodology of building the rankings; \vref{ch4-nbr} outlines the naive Bayes algorithm for label ranking; \vref{ch4-sec:ind.var} discusses the state variables that characterize the information environment; \vref{ch4-sec:results} analyzes the results; and \vref{ch4-sec:conclusion} concludes.

\section{Ranking of financial  analysts}
\label{ch4-sec:ranking}
In the financial literature there has been a long debate on whether financial analysts produce valuable  advice. Some argue that following the advice of financial analysts,  translated as recommendations of buying, holding, or selling a particular stock, does not yield  abnormal returns, i.e.,  returns that are above the required return to compensate for risk. The Efficient Market Hypothesis~\citep{fama1970ecm} states that financial markets are efficient and that any public available information  regarding a stock would be immediately reflected in prices; hence, it would be  impossible to generate abnormal returns based upon past information.

Yet, several authors have since stressed that  there are information-gathering costs and information is not immediately reflected on prices~\citep{grossman1980iie}. As such, prices may not  reflect all the available information at all time because if this were the case, those who spent resources to collect and analyze   information would not have an incentive to do it, because there would not get any compensation for it.

Many trading strategies try to forecast the price movements relying on the historical prices or estimate the intrinsic value of a company. Obviously, this type of research is associated with significant amount of up-front costs to acquire databases, software, etc. On the other hand, financial analysts have these tools and, presumably, skills to identify  stocks that worth be invested. Thus, for an investor, it is cheaper to follow the recommendations of financial analysts rather than perform a proper stock market analysis.


Some authors show that financial analysts' recommendations create value to investors~\citep{womack1996,barber2001}\footnote{\cite{womack1996} finds that  post-recommendation excess returns are not mean-reverting, but are significant and in the direction forecast by the analysts.~\cite{barber2001} finds that over the period of 1986-1996 a portfolio of stocks with the most (least) favorable consensus analyst recommendations yields an average abnormal return of 4.13 (-4.91)\%.}. Assuming that some analysts produce valuable advice it makes sense to rank analysts based on the accuracy of their recommendations.

StarMine rankings are based on financial analysts' accuracy either on TP or EPS forecasts. To rank analysts based on EPS forecasts, StarMine developed a proprietary metric called a Single-stock Estimating Score (SES). This score measures ``... [a] relative accuracy; that is, analysts are compared against their peers. An analyst's SES can range from 0 to 100, with 50 representing the average analyst. To get a score higher than 50, an analyst must make estimates that are both significantly different from and more accurate than other analysts' estimates"\footnote{\url{http://excellence.thomsonreuters.com/award/starmine?award=Analyst+Awards&award_group=Overall+Analyst+Awards}}.


As for target price ranking, StarMine's methodology compares the portfolios based on analysts recommendations. Portfolios are constructed as follows. For each ``Buy'' recommendation, the portfolio is one unit long the stock and simultaneously one unit short the benchmark. ``Strong buy'' gets a larger investment of two units long the stock and two units short the benchmark. ``Hold'' invests one unit in the benchmark (i.e., an excess return of zero). ``Sell" recommendations work in the reverse way. StarMine re-balances its calculations at the end of each month to adjust for analysts revisions (adding, dropping or altering a rating), and when a stock enters or exits an industry grouping.


Recent evidence suggests that top ranked financial analyst affect market participants: prices seem to react more to the recommendations issued by the top-ranked analysts~\citep{emery2009}. As such, StarMine ranking based models can be used to identify such analysts and generate superior estimates (e.g., SmartEstimates\footnote{\url{http://www.starmine.com/index.phtml?page_set=sm_products&sub_page_set=sm_professional&topic=analytical&section=accurate_estimates}}).



The goal of our study is to predict the StarMine rankings. With this purpose, we adapt a Machine Learning  algorithm to predict rankings when given a set of variables that characterize these rankings. We, further, apply the predicted rankings  to build active trading strategies to evaluate quality of predictions against the consensus strategy (giving equal weights to analysts' recommendations).



\section{Label ranking algorithm}
\label{ch4-sec:lr}

The classical formalization of a label ranking problem is the following \citep{vembu2009}. Let $\mathcal{X} = \{\mathcal{V}_1,\ldots,\mathcal{V}_m\}$ be an instance space of  variables, such that $\mathcal{V}_a=\{v_{a,1}, \ldots, v_{a,n_a}\}$ is the domain of nominal variable $a$.  Also, let $\mathcal{L} = \{\lambda_1,\ldots,\lambda_k\}$ be a set of labels, and $\mathcal{Y} = \Pi_{\mathcal{L}}$ be the output space of all possible total orders over $\mathcal{L}$ defined on the permutation space $\Pi$. The goal of a label ranking algorithm is to learn a mapping $h: \mathcal{X} \rightarrow \mathcal{Y}$, where $h$ is chosen from a given hypothesis space $\mathcal{H}$, such that a predefined loss function $\ell: \mathcal{H} \times \mathcal{Y} \times \mathcal{Y} \rightarrow \mathbb{R}$ is minimized. The algorithm learns $h$ from a training set $\mathcal{T}=\{x_i,y_i\}_{i \in \{1, \ldots, n\}} \subseteq \mathcal{X} \times \mathcal{Y}$ of $n$ examples, where $x_i = \{x_{i,1}, x_{i,2}, \ldots, x_{i,m} \} \in \mathcal{X}$ and $ y_i = \{y_{i,1}, y_{i,2}, \dots, y_{i,k}\} \in \mathcal{Y} $. With time-dependent problem in rankings, we replace the $i$ index with $t$; that is $y_t=\{ y_{t,1}, y_{t,2}, \ldots, y_{t,k} \}$ is the ranking of $k$ labels at time $t$ described by $x_t = \{x_{t,1}, x_{t,2}, \ldots, x_{t,m} \} $ at time $t$.


Consider an example of a time-dependent ranking problem presented in \ref{ch4-tab:ranking-example}. In this example, we have three brokers ($k=3$), four independent variables ($m=4$) and a period of 7 quarters. Our goal is to predict the rankings for period $t$, given the values of independent variables and rankings known up to period $t-1$; that is, to predict the ranking for time $t=7$, we use $n=6$ ($t \in \{1 \ldots 6\}$) examples to train the ranking model.


\begin{table}
\caption{Example of label ranking problem}
\begin{center}
 \begin{tabular}{cccccccc}
\toprule
Period & $\mathcal{V}_1$ & $\mathcal{V}_2$ & $\mathcal{V}_3$ & $\mathcal{V}_4$ &\multicolumn{3}{c}{Ranks}\\
\cline{6-8}
&&&&&Alex&Brown&Credit\\
\midrule
<<ch4-table.rank,echo=FALSE,results='asis'>>=
data <- read.csv("~/Dropbox/workspace/Naive.Bayes.separate.functions/cont.data.csv", header = T, sep=",")

ex.x <- matrix('x',nrow = 7,4)
for (i in seq_len(nrow(ex.x)))
{
  for (j in seq_len(ncol(ex.x)))
  {
    ex.x[i,j] <- paste0('$x_{',i,',',j,'}$')
  }
}

print(xtable(cbind(data[1:7,1],ex.x,data[1:7,6:8])),only.contents=T,include.colnames=FALSE,include.rownames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),sanitize.text.function = function(x) x)
@
\bottomrule
 \end{tabular}
 \end{center}
\label{ch4-tab:ranking-example}
\end{table}


\subsection{Naive Bayes algorithm for label ranking}
\label{ch4-nbr}
The naive Bayes for label ranking (NBLR)  will output the ranking with the higher $P_{LR}(y|x)$ value \citep{aiguzhinov2010}:
\begin{align}
\label{ch4-eq:nb}
\hat{y}&=\argmax_{y \in \Pi_{\mathcal{L}} }P_{LR}(y|x)= \\ \notag
&=\argmax_{y\in \Pi_{\mathcal{L}} }P_{LR}(y)\prod_{i=1}^m P_{LR}(x_i|y)
\end{align}
where $P_{LR}(y)$ and $P_{LR}(x_i|y)$ are the prior and conditional label ranking probabilities af a nominal variable $x$ of attribute $a$, ($v_{a}$), respectively, and they are given as follows:

\begin{equation}
P_{LR}(y) = \frac{\sum_{i=1}^{n} \rho(y,y_i)}{n}
\label{ch4-eq:prior}
\end{equation}

\begin{equation}
P_{LR}(x_i|y)= \frac{\sum_{i: x_{a} = v_{a}}\rho(y, y_i)}{|\{i: x_{a} = v_{a}\}|}
\label{ch4-eq:cond}
\end{equation}
where  $\rho(y,y_i)$ is the similarity between rankings obtained from the Spearman ranking correlation:

\begin{equation}
\rho(y,y_i)=1-\frac{6\sum_{j=1}^k(y-y_{i,j})^2}{k^3-k}
\label{ch4-eq:spearman}
\end{equation}

Similarity and probability are different concepts; however, a connection as been established between probabilities and the general Euclidean distance measure \citep{vogt2007}. It states  that maximizing the likelihood is equivalent to minimizing the distance (i.e., maximizing the similarity) in a Euclidean space. The predicted ranking for an example $x_i$ is the one that will receive the maximum posterior label ranking probability $P_{LR}(y|x_i)$.


\subsubsection{Continuous independent variables}
\label{ch4-sec:cont}
In its most basic form, the naive Bayes algorithm cannot deal with continuous attributes. The same happens with its adaptation for label ranking \citep{aiguzhinov2010}. However, there are versions of the naive Bayes algorithm for classification that support continuous variables \citep{bouckaert2005}. The authors modify the  conditional label ranking probability  by utilizing the Gaussian distribution of the independent variables. We apply the same approach  in defining the conditional  probability of label rankings:

\begin{equation}
\label{ch4-cont}
P_{LR}(x|y)=\frac{1}{\sqrt{2\pi}\sigma(x|y)}e^\frac{(x-\mu(x|y))^2}{2\sigma^2(x|y)}
\end{equation}
where $\mu(x|y)$ and $\sigma^2(x|y)$ weighted  mean and weighted variance, defined as follows:

\begin{equation}
\label{ch4-mu}
\mu(x|y) =\frac{\sum_{i=1}^n  \rho(y,y_i) x}{\sum_{i=1}^n \rho(y,y_i)}
\end{equation}

\begin{equation}
\label{ch4-eq:sigma}
\sigma^2(x|y)=\frac{\sum_{i=1}^n \rho(y,y_i) [x-\mu(x|y)]^2}{\sum_{i=1}^n \rho(y,y_i)}
\end{equation}

\subsection{Time series of rankings}
The time dependent label ranking (TDLR) problem  takes the intertemporal dependence between the rankings into account. That is, rankings that are similar to the most recent ones are more likely to appear. % than very different ones.
To capture this, we propose the weighted TDLR prior probability:

\begin{equation}
P_{TDLR}(y_t) =\frac{\sum_{t=1}^{n}  w_t \rho(y,y_t)}{ \sum_{t=1}^{n} w_t  }
\label{ch4-eq:timing}
\end{equation}
where $w = \{w_1, \ldots, w_{n}\} \rightarrow \mathbf{w}$  is the vector of weights calculated from the exponential function $\mathbf{w}=b ^{\frac{1-\{t\}_{1}^n }{t}}$. Parameter $b \in  \{1 \ldots \infty\}$ sets the degree of the ``memory'' for the past rankings, i.e.,  the larger $b$, the more weight is given to the last known ranking (i.e, at $t-1$)  and the weight diminishes to the rankings known at $t=1$. %; that is, how fast past rankings should diminish their importance.

As for the conditional label ranking probability, the equation for the weighted mean (\ref{ch4-cont}) becomes:
\begin{equation}
\label{ch4-mu.w}
\mu(x_{t}|y_t) = \frac{\sum_{t=1}^n  w_t \rho(y,y_t) x_{t}}{\sum_{t=1}^n \rho(y,y_t)}
\end{equation}
\begin{equation}
\label{ch4-sigma}
\sigma^2(x_{t}|y_t)=\frac{\sum_{i=1}^n w_{t} \rho(y,y_t) [x_{t}-\mu(x_{t}|y)]^2}{\sum_{i=1}^n \rho(y,y_t)}
\end{equation}

\section{State variables}
\label{ch4-sec:vvs}
Several studies try to analyze  factors that affect the performance of analysts~\citep{clement1999,brown2003,jegadeesh2004}.  However, most of these papers look at the individual characteristics of analysts such as their job experience, their affiliation,  education background, industry specializations. These variables are very important to characterize the relative performance of the analysts in general but they miss the ``state-of-the-world" component, i.e., variables that all analysts are affected. We believe that rankings of analysts capture this component in full.

Ranking means that there are differences in opinion among the analysts concerning the future performance of a company.  This implies that there is  a variability (dispersion) in analysts' forecasts for a given stock in a given quarter~\citep{diether2002}. Thus, we can analyze  the analysts forecasts' dispersion in terms of its origin and factors that affect it; hence, assuming the same variables affect the rankings. It follows that the variation in rankings is due to the different ability of the analysts to interpret the informational environment (e.g., whether the market is bull or bear). We, thus, select and analyze variables that describe this environment.

To capture the full spectrum of the analyst's decision making process, we select  variables based on different levels of information availability: analyst-specific,  firm-specific  and general economy. In each level, we want a variable to be responsible for information asymmetry and uncertainty. Thus, we believe that these two domains are responsible for the differences in analysts' opinions.

\subsection{Analyst-specific variables}
On an analyst level, we want to capture the asymmetry and uncertainty among the analysts~\citep{barron1998,barron2009,zhang2006,sheng2012}. Particularly,~\cite{barron2009} point our that the reason for dispersion is either uncertainty or information asymmetry. They find that prior to earnings announcement the uncertainty component prevail, whereas around the time of earnings announcement, information asymmetry is responsible for changes in analysts' opinions.

To capture the states of the dispersion, we use the same set of variables defined in~\cite[page 333]{barron2009}:

\begin{eqnarray}
SE_{i}&=&(ACT_{i}-\overline{FE_i})^2 \nonumber\\
disp_i&=&\sum_{j=1}^{N} \frac{(FE_{j,i}-\overline{FE_i})^2}{(N-1)} \label{ch4-eq:disp}\\
uncert_i&=&\sum_{j=1}^{N} \left(1-\frac{1}{n}\right) \times disp_i + SE_i \label{ch4-eq:uncert}\\
assym_i& = & 1-\frac{SE_i-\frac{disp_i}{n}}{uncert_i} \label{ch4-eq:assym}
\end{eqnarray}
where $SE$ is the squared error in mean forecast; $\overline{FE}$ is the average per analysts EPS forecast error (see \ref{ch4:eps-rank});  and $N$ is the number of analysts in a given quarter for a given stock $i$.

\ref{ch4-eq:disp} calculates the dispersion among the analysts which is a variance of EPS forecasts of all analysts for a given stock. \ref{ch4-eq:uncert} defines the Uncertainty component of the dispersion per~\cite{barron2009}. \ref{ch4-eq:assym} is the proxy for information asymmetry which a function of dispersion, squared mean error, and a number of EPS forecasts.


\subsection{Firm-based variables}

To be consistent with the two paradigms that characterize the state of the analysts, we split the firm-based variables based on their influence on analysts' opinions. They are either uncertainty or the information asymmetry.

\subsubsection{Uncertainty}

The following are the set of the variables and their definitions that we think are responsible for the uncertainty component.

\paragraph{Business risk.} Business risk is associated with the uncertainty in operating results, especially, in operating earnings~\citep{hill1980}. An increase in business risk entails an increase in \emph{ex-ante} volatility of the reported earnings~\citep{parkash1995}.  We believe that  book-to-market ratio can serve as a proxy for the business risk measurement.
\begin{equation}
btm_i=\frac{EQUITY}{MKT.CAP}=\frac{Tot.assts-Tot.liab}{Stocks\times Price}
\end{equation}
where $Stocks$ is the number of stocks outstanding and $Price$ is the close stock price on last day of a quarter.

\paragraph{Financial risk.} Financial risk is responsible for the uncertainty of the future earnings. More debt implies more variability in earnings as managers would try to maximize the value of a stock using the debt; thus, having high risk of default in the future or taking high risk investment projects. The debt-to-equity ratio is used to capture the financial risk~\citep{parkash1995}. We use short-term debt from balance sheet (Notes payable) as a measure for debt.

\begin{equation}
dte_i=\frac{DEBT}{EQUITY}=\frac{ShortTermDebt}{Tot.assts-Tot.liab}
\end{equation}

\paragraph{Size.} The firm size can be used as a proxy for amount of information available for a firm. Thus, larger firm has more news coverage which reduces uncertainty. An investor is likely to find private information about larger firm more valuable than the same information about smaller firm~\citep{bhushan1989}.

Size is measured as the market value (MV) of the firm as following:
\begin{equation}
size_i= \log(Price \times Stocks)
\end{equation}
Consistent with the literature, we use log of market value.


\paragraph{Return variability.}
Return variability influence the uncertainty regarding future earnings~\citep{diether2002,henley2003}. An increase in variability of the abnormal returns is positively correlated with the uncertainty about the earnings; thus, affecting the dispersion among the analysts. To calculate the return variability, we use method provided in~\cite{sousa2008}, where stock return volatility is decomposed into market and stock specific components as follows:
\begin{eqnarray}
\sigma^2_{mkt}&=&\sum_{d\in q} (R_{mkt,d}-\mu_{mkt})^2 \nonumber \\
\sigma^2_{i}&=&\sum_{d \in q} (R_{i,d}-R_{mkt,d})^2 \nonumber \\
s.ret_i=Var(R_{i,q})&=&\sigma^2_{mkt}+\sigma^2_{i} \label{ch4-eq:ret.vol}
\end{eqnarray}
where $R_{mkt,q}$ is the market return over sample period; $\mu_{mkt}$ is the mean of daily market returns; $R_{i,q}$ is an individual stock return; $d$ is the number of trading days in period $q$.

\subsubsection{Information Asymmetry variables}
\paragraph{Accruals.}
Accruals, as a part of  earnings, is one of the variables that cause the information asymmetry between managers of a firm and investors. Studies have shown that presence of asymmetry is a necessary condition for the earnings management~\citep{trueman1988,richardson2000}. To be more specific, it is the discretionary part of the accruals that causes  the information inefficiency  in the earnings management~\citep{richardson2000,ahmed2005}. We calculated total accruals-to-total assets ratio defined in~\cite{creamer2009}:

\begin{eqnarray}
accr_i=\frac{\Delta C.As - \Delta Cash - (\Delta C.Lb. - \Delta C.Lb.D) - \Delta T - D\& A_q}{(T.As. - T.As._{q-4})/2}
\end{eqnarray}
where $\Delta X=X_q-X_{q-1}$; $C.As$ -- current assets; $C.Lb$ -- current liabilities; $C.Lb.D$ -- debt in current liabilities; $T$ -- deferred taxes; $D\&A$ -- depreciation and amortization; and $T.A$ -- total assets.



\paragraph{Sector-based variables.} The industry specific variables that cause the dispersion in the analysts' forecasts are connected  with the uncertainty concept. One of the variables that is suggested to capture is the variability in the industry Producer Price Index (PPI)~\citep{henley2003}.
\begin{equation}
sec.ret_i = \sigma (\log PPI_{sec})
\end{equation}
where $\sigma (\log PPI_{sec})$ is the standard deviation of the log of SIC sectors' produce price index.


\subsection{Macroeconomics variables}
In the last set of the state variables, we want to capture the macroeconomic conditions which affect the analysts' dispersion. For example, different states of the economy are based on  different levels of ``GNP--inflation" combinations~\citep{lev1993,hope2005}. When economy is booming, i.e. ``high GNP-low inflation" state,~\cite{lev1993} observe the significant increase in firms' Capital Expenditures coefficient. This implies that firms start enjoy capital investment due to the low cost of capital. This state of the economy produces less uncertainty. In the ``medium GNP-high inflation" state of the economy, there is an increase in R\&D expenditures, which, from the above mentioned analysis, may spur high level of information asymmetry based on the increase R\&D activities. Finally, in the ``low GNP-high inflation" state,~\cite{lev1993} observe the Doubtful Receivables coefficient is the largest implying that at this recession state many firms go bankrupt or default on the loans -- a signal of high uncertainty in the economy. All these states produce the dispersion of the analysts' forecasts.

We select the following set of the macroeconomic variables:
\begin{itemize}
\item $gnp$ = Gross National Product;
\item $infl$ = Inflation rate;
\item $t.bill$ = Interest rate (90-days T-bill rate);
\item $vix.ret$ = Market variability (CBOE VIX index)
\end{itemize}


We selected state variables consistent with \cite{aiguzhinov2015b}, i.e., we use variable that have more than 10\% contribution to the rankings. \ref{ch4:tab-dp} demonstrates the total discriminative power of state variables for different states for EPS ranking. The variables that contribute the most to the rankings are:
<<ch4-state-vvs,echo=F,results='asis',warning=F>>=
cat('\\{',paste(sapply(vvs.paper.name[sort(unique(unlist(as.vector(apply(share.vvs>10,2,which)))))],function(i) {paste0('\\emph{',i,'}')},USE.NAMES=F),collapse='; '),'\\}',sep='')
@
.




\section{Trading Strategy}
\label{ch4-sec:trading}


We follow the Black-Litterman procedure developed in~\cite{aiguzhinov2015a}:
\begin{enumerate}
\item For each stock, at the beginning of quarter $q$, we forecast the rankings of all analysts that we expect to be at the end of the quarter $q$;
\item Based on these  predicted rankings and analysts' price targets,  we define $Q_{q,s}$ and $\Omega_{q,s}$ (see (\ref{ch4-def-q})  and (\ref{ch4-def-omega}));
\item Using market information available at the last day of quarter $q-1$, we obtain the market inputs;
\item Apply BL model to get  optimized portfolio weights and buy/sell stocks accordingly;
\end{enumerate}

The model requires form an investor two inputs: the vector of expected returns and the confidence of these returns. The vector of returns is where we rely on the knowledge of the analysts. We use two types of expected returns: 1) ones that are based on the consensus among analysts about future stock performance; 2) ones that are based on the rankings of analysts

\subsection{Defining $Q$}
\label{ch4-def-q}

For the consensus strategy, we use median of expected returns for a particular stock $i$:
\begin{equation}
\label{ch4-consq}
Q_{cons,i}= \mathrm{median} \left\{r_{j,i}\right\}
%\frac{1}{N} \sum_{j=1}^{N} r_{j,i}
\end{equation}
%$N$ is the number of analysts with a valid TP report and
where $r_{j,i}=TP_{j,i}/P_{i}-1$  is last known analyst's $j$ expected return computed using the analyst price target $TP_{j,i}$ and stock price $P_{i}$\footnote{Consistent with the literature, we use stock price 3 days \emph{ex-ante} the TP announcement. This is done to avoid any information leakage around new TP announcement day~\citep{bonini2010}}.

For the strategies that weight the analysts' estimates of expected return the weight of each analyst $j$ is based on his/her rank such that the top analyst has the weight of 1 and then the weights diminish as the rank increases.


\begin{equation}
\label{ch4-eq:weight}
w_{j,i}=1-\frac{rank_{j,i}-\min_i{ \{rank \} }}{\max_i{\{rank \}}}
\end{equation}

The expected rank-weighted return is thus:
\begin{equation}
\label{ch4-rankq}
Q_{rank,i}=\frac{\sum_{j=1}^{N} (w_{j,i} \times r_{j,i})}{\sum_{j=1}^{N} w_{j,i}}
\end{equation}
$N$ is the number of analysts.

As mentioned above, we use both target price and EPS accuracy rankings.

\subsubsection{Target Price ranking}
%%% change s to i for stock
Analysts are ranked on the basis of Proportional Mean Absolute Forecast Error (PMAFE) that measures the accuracy of a forecast ~\citep{clement1999,brown2001,ertimur2007}. First,  we define the forecast daily error  $FE_{j,i}$ as the absolute value of the difference between analyst' target price $TP_{j}$ and the daily stock price $P$ for each stock $i$:

\begin{equation}
\label{ch4-dfe}
FE_{j,i}^{TP}=|{P_{i}-TP_{j,i}}|
\end{equation}
The PMAFE is given as:
\begin{equation}
\label{ch4-tp:pmafe}
PMAFE_{j,i}^{TP}=\frac{FE_{j,i}^{TP}}{\overline{FE_{i}^{TP}}}
\end{equation}
where $\overline{{FE}_{i}^{TP}}$ is the average forecasting error across analysts. The target price is fixed over the quarter unless it gets revised.

The rank  that enters \ref{ch4-eq:weight} is average analyst's $PMAFE^{TP}$ over a particular quarter:
\begin{equation}
\overline{PMAFE_{j,i}^{TP}}=\frac{1}{D} \sum_{t=1}^{D} PMAFE_{j,t,i}^{TP}
\end{equation}

\begin{equation}
\label{ch4-tp:rank}
rank_{j,i}=\mathrm{rank}_{j=1}^{N} \left\{ \overline{PMAFE_{j,i}^{TP}} \right\}
\end{equation}
where $D$ are the number of trading days in a quarter and $N$ is the number of equity research firms with a valid TP. \ref{fig:example} shows an example.


\subsubsection{EPS ranking}
\label{ch4:sec-eps}
To compute the EPS rankings, we apply the same procedure as above:
\begin{equation}
FE_{j,i}^{EPS}=|{ACT_{i}-PRED_{j,i}}|
\end{equation}
\begin{equation}
PMAFE_{j,i}^{EPS}= \frac{FE_{j,i}^{EPS}}{\overline{FE_{i}^{EPS}}}
\end{equation}
\begin{equation}
\label{ch4-eps:rank}
rank_{j,i}=\mathrm{rank}_{j=1}^{N} \left\{ PMAFE_{j,i}^{EPS} \right\}
\end{equation}
where $ACT_{i}$ and $PRED_{j,i}$ are the actual quarterly EPS and  analyst $j$'s EPS forecast for stock $i$.


\subsection{Defining the confidence of expected returns $\Omega$}
\label{ch4-def-omega}
The confidence of $Q$ is given by the coefficient of variation (CV) of forecasting errors. For each stock $i$ is given by:

\begin{equation}
\label{ch4-eq-cv}
CV_{i} = \frac{\sigma_i (FE_{i})}{\overline{FE}_{i}}
\end{equation}
where $\sigma_i$ and $\overline{FE}_i$ are the standard deviation and the mean of the forecast errors across analysts for either TP or EPS. A low value of $CV$ reflects consensual estimates of either future prices or EPS.



\subsection{Information sets to define the views}
\label{ch4:inf-set}
To proceed with the predicting the rankings and applying them to a trading strategy, we need to establish which information we  will be using to build the rankings without the ranking model. These rankings will be the inputs to compute the weighted return estimates (``smart estimates") as well as to serve as  baselines to assess the quality of the predicted rankings.

Different analysts' ranks are obtained  if we select different time horizons. If we use only the most  recent information, we will capture the recent performance of the analysts. This, of course, is more sensitive to unique episodes (e.g., a quarter which has been surprisingly good or bad). If, alternatively, we opt to incorporate the entire analyst performance, the ranking is less affected by such events, yet it may not reflect the current analyst ability. We use two information sets: the first uses only the  information about the analyst' performance in period $t-1$; the second, uses all the available  information for that particular analyst. We call the former the \naive{} set and the latter the \default{} set.

In addition to these sets,  we also create a hypothetical scenario that assumes we anticipate perfectly the future analyst accuracy performance  that would only be available at the end of $t$.  This represents the perfect foresight strategy. The perfect foresight refers to analyst rankings not stock prices. Therefore, it serves a performance reference point to evaluate the other trading strategies and performance of the label ranking model. We call this the \tr{} set.

Formalizing information sets considered are:
\begin{itemize}
\item  the \tr{} set%-- a perfect foresight information:
\begin{equation}
\label{q:true}
\widehat{Q_{t}}=Q_{t}
\end{equation}

\item  the \naive{} set % -- $t-$ information:
\begin{equation}
\label{q:naive}
\widehat{Q_{t}}=Q_{t-1}
\end{equation}

\item  the \default{}  set%-- the entire history of analysts
\begin{equation}
\label{q:default}
\widehat{Q_{t}} = \frac{1}{T} \sum_{t=1}^{T} Q_{t}
\end{equation}

\end{itemize}
where $Q_{t}$ is the analysts' expected rank-weighted stock return (\ref{ch4-rankq})


\section{Data and experimental setup}
\label{ch4-sec:rankings}
To implement  the trading strategy, we focus on the  S\&P500 stocks. The period of the strategy experiments runs from the first quarter of 2001 until the last quarter of 2009. We get the analysts price target data from ThomsonReuters I/B/E/S dataset; the list of S\&P constituents and stock daily prices data are from DataStream as well as the market capitalization data.  The total number of analysts in price target dataset is \Sexpr{core.dt[,.N,by=Broker][,.N]}  covering \Sexpr{nrow(stocks.m)} S\&P 500 stocks all. Consistent with other studies on analysts' price targets, we  truncate our sample due to stock-split misalignment errors found on I/B/E/S data. As we mention, we weight the analysts' expected returns $r_{j,i}$ by the analysts' rank. This assures that very optimistic analysts' would be penalize by the lower rank and still contribute to $Q_{i}$. Given the fact that analysts issue price targets annually, we assume that an analyst keeps her price target forecast open for one calendar year until it revised or expires after one year.


table (\ref{ch4-tab:stat}) shows the statistics of the expected analysts return $r_{q,a,s}$. Consistent with the literature~\citep{da2011,bradshaw2012,zhou2013}, we find the average expected annual analysts' return to be highly upward biased.

\subsection{Ranking contingency results}
\label{ch4-tab:rank-contin}
We consider  three terciles (\textit{top}, \textit{medium}, \textit{bottom}). In one particular quarter ($t$), we place  analysts at one of these bins which corresponds to a tercile. We, then,  check analysts position at the immediate next quarter ($t+1$) and after one year ($t+4$).

Beforehand, we convert the rankings into scores as follows:
\begin{equation}
\label{eq:score}
score_{j,i}=\frac{rank_{j,i}}{\max{rank_i}}
\end{equation}

To get the cross-sectional values of scores across different stocks, we take the average of $score_{j,i}$
\begin{equation}
\label{ch4-eq:mean-score}
\overline{score_{j}}= \frac{1}{k} \sum_{s=1}^{k} score_{j,i}
\end{equation}
where $k$ is number of stocks followed by a particular analyst $j$.

\ref{ch4:tab-rank-stat} shows a contingency analysis of the ranks. We consider the rankings based on the feasible information sets. Panel A shows the dynamics of each tercile for rankings based on target price  accuracy for the \naive{} and \default{} sets. We observe that analysts exhibit strong ranking consistency as, on average, they stay at the same tercile after one quarter. For the \naive{} case, of the top (bottom) most accurate (inaccurate) analysts in the previous quarter \Sexpr{pt.cont.tab[1,1,2,1]*100}\% (\Sexpr{pt.cont.tab[3,3,2,1]*100}\%) remain in that same tercile after one quarter. After one year the corresponding figures are lower respectively \Sexpr{pt.cont.tab[1,1,2,2]*100}\% and \Sexpr{pt.cont.tab[3,3,2,2]*100}\% for the top and bottom terciles. In case of the \default{}, the analyst consistency is even more profound with \Sexpr{pt.cont.tab[1,1,3,1]*100}\% (\Sexpr{pt.cont.tab[3,3,3,1]*100}\%) of analysts that stayed on top (bottom) in previous quarter remained in the same tercile in the next quarter. Even after one year, the consistency does not change much with \Sexpr{pt.cont.tab[1,1,3,2]*100}\% of analysts stayed on top and \Sexpr{pt.cont.tab[3,3,3,2]*100}\% remained at the bottom.

In the case of EPS \naive{} ranking  (panel B) \Sexpr{eps.cont.tab[1,1,2,1]*100}\% and  \Sexpr{eps.cont.tab[3,3,2,1]*100}\% (\Sexpr{eps.cont.tab[1,1,2,2]*100}\% and  \Sexpr{eps.cont.tab[3,3,2,2]*100}\%) of the analysts  remained in the top and bottom terciles, respectively,  after one quarter (year). For the case of \default{} ranking, \Sexpr{eps.cont.tab[1,1,3,1]*100}\% and  \Sexpr{eps.cont.tab[3,3,3,1]*100}\% (\Sexpr{eps.cont.tab[1,1,3,2]*100}\% and  \Sexpr{eps.cont.tab[3,3,3,2]*100}\%) of the analysts stayed on top and bottom respectively after one quarter (year).

These results are consistent with the recent findings of~\cite{hilary2013} on analyst forecast consistency.

%'
%' \begin{table}
%' \caption{Example of label ranking}
%' \ The table shows the example of label ranking problem. In this example, we have three brokers and values of independent variables $x_1 \ldots x_4$. Our goal is to predict the rankings for the period $t+1$, given the values of independent variables and rankings known up to period $t$. For example, at  $t=3$ \true{} is $\{1,2,3\}$, \naive{} is $\{2,3,1\}$, and \default{} is $\{A=(1+2)/2,B=(2+3)/2,C=(3+1)/2\} \Rightarrow \{1.5,2.5,2.0\} \Rightarrow \{1,3,2\}$.
%' \begin{center}
%'  \begin{tabular}{cccccccc}
%' \toprule
%' Period & $x_1$ & $x_2$ & $x_3$ & $x_4$ &\multicolumn{3}{c}{Ranks}\\
%' \cline{6-8}
%' &&&&&Alex&Brown&Credit\\
%' \midrule
%' <<ch4-table.rank,echo=FALSE,results='asis'>>=
%' data <- read.csv("~/Dropbox/workspace/Naive.Bayes.separate.functions/cont.data.csv", header = T, sep=",")
%' print(xtable(data[1:7,2:8],display=c('f','f','f','f','f','d','d','d')),only.contents=T,include.colnames=FALSE,include.rownames=T,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."))
%' @
%' \bottomrule
%'  \end{tabular}
%'  \end{center}
%' \label{ch4-tab:ranking-example}
%' \end{table}


% Descritive rankings
%\begin{landscape}
\begin{table}
\caption{Analysts' ranking consistency}
\label{ch4:tab-rank-stat}
\ This contingency table shows changes in analysts'  \textit{top}, \textit{middle}, \textit{bottom} ranking bins. Panel A (Panel B) depicts the dynamics of the analysts' ranks  based on the accuracy in target prices (EPS forecasts). Rankings of \naive{} is the case of ranking information know at $t-1$ and the \default{}  is the case of using all ranking information for up to $t-1$. %State \last{} is the last known value of the independent variables; \diff{} is the first differencing; \random{} is the random part of the time series decomposition, and \rollsd{} is the moving standard deviation for previous 8 quarters.

\begin{tabularx}{\linewidth}{r*{10}{Y}}
    \toprule
&\multicolumn{3}{c}{$top_t$}&\multicolumn{3}{c}{$middle_t$}&\multicolumn{3}{c}{$bottom_t$} \\
\midrule
&$top$&$mid$&$bottom$&$top$&$mid$&$bottom$&$top$&$mid$&$bottom$\\
\midrule
\multicolumn{10}{l}{\textbf{Panel A: TP}}\\
<<ch4-desc-rank-pt-t1,echo=F,results='asis'>>=
dimnames(pt.cont.tab)[[1]] <- c('top','mid','bot')
dimnames(pt.cont.tab)[[2]] <- c('top+1','mid+1','bot+1')
dimnames(pt.cont.tab)[[3]] <- c('\\tr{}','\\naive{}','\\default{}','\\last{}','\\diff{}','\\random{}','\\rollsd{}')
tab.r <- acast(melt(pt.cont.tab[,,,'t']),Var3~Var1+Var2,value.var='value')*100
#rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r[2:3,],hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,add.to.row=list(pos=list(0),command=c('&&\\multicolumn{8}{c}{$t+1$}\\\\ \n')),sanitize.text.function = function(x) x)

tab.r <- acast(melt(pt.cont.tab[,,,'t+4']),Var3~Var1+Var2,value.var='value')*100
#rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r[2:3,],hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,add.to.row=list(pos=list(0),command=c('&&\\multicolumn{8}{c}{$t+4$}\\\\ \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}
\begin{tabularx}{\linewidth}{r*{10}{Y}}
\midrule
\multicolumn{10}{l}{\textbf{Panel B: EPS}}\\
\midrule
%&&$top$&$middle$&$bottom$&Sum\\
<<ch4-desc-rank-eps-t1,echo=F,results='asis'>>=
dimnames(eps.cont.tab)[[3]] <- c('\\default{}','\\last{}','\\diff{}','\\random{}','\\rollsd{}','\\naive{}','\\tr{}')
tab.r <- acast(melt(eps.cont.tab[,,c(7,6,1,2,3,4,5),'t']),Var3~Var1+Var2,value.var='value')*100
#rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r[2:3,],hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,add.to.row=list(pos=list(0),command=c('&&\\multicolumn{8}{c}{$t+1$}\\\\ \n')),sanitize.text.function = function(x) x)

tab.r <- acast(melt(eps.cont.tab[,,c(7,6,1,2,3,4,5),'t+4']),Var3~Var1+Var2,value.var='value')*100
#rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r[2:3,],hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,add.to.row=list(pos=list(0),command=c('&&\\multicolumn{8}{c}{$t+4$}\\\\ \n')),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}
%\end{landscape}

\section{Empirical Results}
\label{ch4-sec:results}

\subsection{Ranking predictions}

\begin{table}
\caption{Discriminative power contribution}
\ The table demonstrates the contributions of each of the state variable to the analysts' rankings for different states of the world. State \last{} is the state with no dynamics in values of the variables, \diff{} is the state with first-difference in values, \random{} is the state that captures the random part of values time-series decomposition,  and \rollsd{} is the state of values sliding 8 quarters standard deviation.

\begin{tabu} to \linewidth{r*{5}{Y}}
\toprule
Variable&\last{}&\diff{}&\random{}&\rollsd{} \\
\midrule

<<chap4-eps-dp,echo=F,results='asis',warning=F>>=

print(xtable(apply(round(share.vvs,3),2,function(i){ifelse(i>10,paste0('\\textbf{',i,'}'),i)})),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,sanitize.text.function=function(x) x)
@

\bottomrule
\end{tabu}
\label{ch4:tab-dp}
\end{table}



We report the ranking prediction results in \ref{ch4:tab-rank}. Panel A (B)  presents annual and total ranking accuracy measured as the average Spearman rank correlation between the \true{} and all other label ranking methods obtained from the analysts' target price (EPS) forecasts. The more accurate is the ranking prediction the higher is the accuracy. In panel A, we observe that  predicted rankings based on target prices are constantly outperform the \default{} baseline but fail  the  \naive{}.

The average accuracy of the predicted rankings based on the EPS forecasts (panel B) demonstrates quite different results. We report that rankings predicted  with \diff{} state of the variables are more close to \tr{} than those of the baselines.  \ref{ch4:fig-accur} depicts the reported average Spearman correlations. We apply the local polynomial regression fitting~\citep{cleveland1992} to smooth the series for a better presentation.

The top panel of \ref{ch4:fig-accur} plots the case of the EPS based rankings. Looking at baselines rankings, i.e., rankings that obtained without label ranking model, we observe that for the first half of the sample period (from 2000 until 2004) the \naive{} rankings  demonstrate a constant increase in the average ranking accuracy. This means that during this period, rankings of the analysts, on average, did not change from one quarter to another. Starting from 2004, the average accuracy of the \naive{} rankings begins to decrease until the end of the sample period.

A somewhat interesting pattern shows the average accuracy of the \default{} ranking: similar to the \naive{}, it also has been increasing until 2005 but running below the \naive{}. However, after 2005, the \default{} ranking accuracy outran the \naive{}. Moreover, in times of the financial crisis of 2007-2009, the \default{} demonstrated an increasing trend in ranking accuracy.

As far as the predicted rankings are concerned, we observe that the \diff{} average accuracy has been constantly above the other methods and only during the period of crisis it dropped significantly. In fact, except for the \random{}, all predicted methods reach the maximum average accuracy at around 2007, a pre-crisis time, and all, except for the \default{}, show a downward trend afterwards.

The bottom panel of \ref{ch4:fig-accur} plots the average accuracy of rankings based on the price targets. We observe that compared to the EPS case, the smoothed series of ranking accuracy are less volatile. The accuracy of ranking based on the \naive{} information are constantly above all others; only by the end of the sample period it begins to drop. The \default{} case, on the contrary, drops rapidly at the beginning of the sample period and continues to decrease in value until the end of the period. The accuracy of predicted rankings falls in between of the \naive{} and the \default{} cases. We observe that the cases of \diff{} and \random{} show a constant increase in accuracy starting from 2005-2006  and, by the end of the sample period, the \random{} almost reaches the level of the accuracy of \naive{} case while the \diff{} is still in the upward trend.

Overall, the results of experiment of the predicting the rankings show that it is possible to model the independent variables under different dynamic states with the rankings. Moreover, the label ranking model can predict the rankings that outperform, in terms of average accuracy, the ones  obtained from the past analysts' relative performance. Concretely, we report that the predicted rankings based on the EPS forecasts outperform the baselines under \diff{} dynamic state of independent variables.




\subsection{Trading strategies}

We perform active trading based on the Black-Litterman strategy outlined in \cite{aiguzhinov2015a}; namely, we select rankings based on the analysts' price targets. This done due to the fact that the analysts' stock expected returns also derive from the price targets.

The results are presented in \ref{ch4-tab:strategy}. Panel A reports the performance of \market{} (passive strategy). This strategy showed annualized cumulative return of \Sexpr{round(bl.results[8,1,1,1],2)}\% and annualized Sharpe ratio of \Sexpr{round(bl.results[8,1,3,1],3)}. The average number of stocks used per quarter is \Sexpr{round(bl.results[8,1,4,1])} and the turnover ratio of strategy is \Sexpr{round(bl.results[8,1,5,1],3)} which demonstrates the ins/outs of the S\&P 500 constituents list.

Panel B of the table demonstrates the results of trading with consensus among analysts about price target. The annualized cumulative return of this strategy under the \recent{} (\default{}) information set is \Sexpr{round(bl.results['recent',1,1,con],2)}\% (\Sexpr{round(bl.results['all-time',1,1,con],2)}\%) and the Sharpe ratio is  \Sexpr{round(bl.results['recent',1,3,con],3)} (\Sexpr{round(bl.results['all-time',1,3,con],3)}). This strategy outperforms the \Market{} in both the information sets with the \default{} outrunning the \naive{} in terms of the annualized cumulative returns.

Panel C of the table demonstrates the results of trading with rankings based on price target. Observe that consistent with our assumption, the \true{} resulted in the maximum possible annual cumulative return and the Sharpe ratio (\Sexpr{round(bl.results['true',1,1,tp],2)}\% and  \Sexpr{round(bl.results['true',1,3,tp],3)} respectively). Given the hypothetical assumption of \true{} set, it is not feasible to implement; thus,  the next best feasible strategy is
<<ch4-pt.max.strat,echo=FALSE,results='asis'>>=
cat(paste0('\\',gsub('[[:punct:]]','',names(which.max(bl.results[2:8,1,1,tp]))),'{}'))
@
which is based on the predicted rankings from the label ranking model. This strategy yields an annualized cumulative return of \Sexpr{max(bl.results[2:8,1,1,tp])}\% and the Sharpe ratio of \Sexpr{max(bl.results[2:8,1,3,tp])} which are higher than those of the \textit{CONS} and \Market{} strategies. Moreover, we report that all strategies based on the predicted rankings with the dynamic states yield higher annualized cumulative returns than those  based on the rankings from the  \naive{} and the \default{} information sets. The analysis of the sub-periods performance of the \diff{} strategy is depicted in~\ref{ch4-tab:substrategy}. The table shows the value of Sharp ratio for the 5-year periods. We observe that the \diff{} strategy was dominant in most of the periods.

To test the significance of the annualized cumulative returns of strategies based on the predicted rankings we perform a null-hypothesis pairwise test when \emph{null} is the difference in returns is zero. \ref{ch4:tab-sig} presents the test results. We report that the returns of the strategies based on the predicted rankings with the \diff{} and \random{} dynamic states are statistically significant at 1\% when compared with the returns of all other strategies. The test accepts the \emph{null} for the returns obtained for the strategies based on the predicted rankings of the \last{} and \rollsd{} states.



\ref{ch4-fig:bl-results} plots the graphical representation of the cumulative returns for all  trading strategies. We observe that for the case of strategy based on the analysts' rankings, the \true{} strategy is always on top of all the others. This implies that in the settings where analysts' expected returns and rankings are based on price targets, an investor can gain a maximum results from trading strategy.


\section{Conclusion}
\label{ch4-sec:conclusion}
Some institutions, such as StarMine, rank financial analysts based on their accuracy and investment value performance. These rankings are published and are relevant: stocks favored by top-ranked analysts will probably receive more attention from investors. Therefore, there is a growing interest in understanding the relative performance of analysts. In this paper we show that top ranks stay at top from quarter to quarter. Given this fact, we developed an algorithm that is able to predict the rankings based on state variables that characterize the information environment of the analysts. Further, we designed and operationalized a trading strategy based on the Black-Litterman model with rankings as inputs. We obtained positive successful results from trading that out-performs both the market and the \naive{} method of ranking prediction.

The results of our work open many opportunities for future research. For example, in this paper we use the classical interpretation of the Black-Litterman model where risk is measured as a standard deviation. Recent work suggests utilizing more complex measures such as value-at-risk and high-moments approaches.

%We analyzed the rankings and concluded that most errors in rankings were done at the bottom. Consistent with the literature, we confirm that there exists a subset of analysts who issue informative forecasts and this subset is consisted form one period to another.
%We perform two tasks of the label ranking problem of the financial analysts. First, we successfully perform the predicting part of the problem by adapting the existing LR algorithm. Our results were able to outperform both of the baselines: the naive rankings and the default. Based on the average ranking accuracy,  the best result of the experiment was achieved with a method in which the attributes were aggregated applying the rolling standard deviation. This finding suggests that analysts, in the  process of their interpretation of information, rely on  stability of the time series at least for 8 quarters.

%We applied the forecasted rankings to the simulations of stock trading and reported a profitable trading strategy based on the annualized cumulative returns. We created a perfect foresight portfolio in which we would know the actual rankings \textit{ex-ante}. The portfolio based on these rankings out-performs the market. We conclude that, rankings can identify the best analysts and leveraging the recommendations of these analysts produces the profitable outcomes. In addition, we conclude that the best possible scenario of trading strategies is the one that base the rankings on price target errors. It follows, that investors are better off analysts who issue the price target forecast.

%For the future research we would like to develop new methods in forecasting the rankings of the analyst that can out-perform the simple last period ranking method.




\begin{table}
  \caption{Sample Statistics}
  \label{ch4-tab:ret-stat}
\ This table shows the average number of target prices per stock per quarter.

\begin{tabularx}{\linewidth}{r*{6}{Y}}
\toprule
    & Min&Mean&Median&Max&Std.dev\\
%\midrule
%\multicolumn{6}{l}{\textbf{Panel A: TP}} \\
\midrule
<<ch4-desc-pt,echo=F,results='asis',warning=FALSE>>=
print(xtable(acast(melt(brok.full.stat.pt,id.vars=c('year')),year~variable,value.var='value'),display=c('s','d','f','d','d','f'),digits=3),only.contents=T,include.colnames=FALSE,include.rownames=T,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(11),command=c('\\midrule \n')))
@
\bottomrule
\end{tabularx}
\end{table}
%'
%' \begin{tabularx}{\linewidth}{r*{6}{Y}}
%' \midrule
%' \multicolumn{6}{l}{\textbf{Panel B: EPS}} \\
%' \midrule
%' <<ch4-desc-eps,echo=F,results='asis',warning=FALSE>>=
%' print(xtable(acast(melt(brok.full.stat.eps,id.vars=c('year')),year~variable,value.var='value'),display=c('s','d','f','d','d','f'),digits=3),only.contents=T,include.colnames=FALSE,include.rownames=T,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(11),command=c('\\midrule \n')))
%' @
%' \bottomrule
%' \end{tabularx}
%' \end{table}


\begin{table}
  \caption{Descriptive statistics of views}
  \label{ch4:view-stat}
\ This table shows the descriptive statistics of views (expected returns) based on the consensus (median) among the analysts (panel A) and target price rankings (panel B). State \last{} is the state with no dynamics in values of the variables, \diff{} is the state with first-difference in values, \random{} is the state that captures the random part of values time-series decomposition,  and \rollsd{} is the state of values sliding 8 quarters standard deviation.

\begin{tabularx}{\linewidth}{r*{4}{Y}}
\toprule
& Mean (in \%)&Median (in \%)&Std.dev\\
\midrule
<<ch4desc-q-cons,echo=F,results='asis'>>=
test.a[,,,1:2] <- test.a[,,,1:2]*100
dimnames(test.a)[[2]] <- c('\\tr{}','\\naive{}','\\default{}','\\last{}','\\diff{}','\\random{}','\\rollsd{}')
print(xtable(acast(melt(test.a[12,,'CONS',1:3]),Var1~Var2,value.var='value'),auto=T),only.contents=T,include.colnames=FALSE,NA.string='-',hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\multicolumn{4}{c}{\\textbf{Panel A: Consensus}} \\\\ \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}

\begin{tabularx}{\linewidth}{r*{7}{Y}}
  \midrule
<<ch4desc-q-tp,echo=F,results='asis'>>=
print(xtable(acast(melt(test.a[12,,'PT',1:3]),Var1~Var2,value.var='value'),display=c('s','f','f','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\multicolumn{4}{c}{\\textbf{Panel B: TP}} \\\\ \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}
%'   \begin{tabularx}{\linewidth}{r*{7}{Y}}
%'   \midrule
%' <<ch4desc-q-eps,echo=F,results='asis'>>=
%' print(xtable(acast(melt(test.a[12,,'EPS',1:3]),Var1~Var2,value.var='value'),display=c('s','f','f','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\multicolumn{4}{c}{\\textbf{Panel C: EPS}} \\\\ \n','\\midrule \n')),sanitize.text.function = function(x) x)
%' @
%' \bottomrule
% \end{tabularx}
%\end{table}


\begin{table}
\caption{Average ranking accuracy}
\ The table presents the average Spearman correlation between \tr{} and  predicted rankings that are based on accuracy of price target (panel A) and on EPS forecasts (panel B) compared to baselines: \tr{} shows the case of the known future information; \naive{} is the case of ranking information know at $t-1$, and the \default{}  is the case of using all ranking information for up to $t-1$. State \last{} is the state with no dynamics in values of the variables, \diff{} is the state with first-difference in values, \random{} is the state that captures the random part of values time-series decomposition,  and \rollsd{} is the state of values sliding 8 quarters standard deviation.

\begin{tabu} to \linewidth{r*{8}{Y}}
\toprule
Year&\true{}&\naive{}&\default{}&\last{}&\diff{}&\random{}&\rollsd{} \\
\midrule
\multicolumn{8}{l}{\textbf{Panel A: TP}} \\
\midrule
<<chap4-tp-rank,echo=F,results='asis',warning=F>>=
print(xtable(pt.rank,digits=4),only.contents=T,include.colnames=F,include.rownames=F,hline.after=NULL,add.to.row=list(pos=list(10),command=c('\\midrule \n')),sanitize.text.function=function(x) x)
@
\midrule
\end{tabu}

\begin{tabu} to \linewidth{r*{8}{Y}}
\multicolumn{8}{l}{\textbf{Panel B: EPS}} \\
\midrule
<<chap4-eps-rank,echo=F,results='asis',warning=F>>=
print(xtable(eps.rank,digits=4),only.contents=T,include.colnames=F,include.rownames=F,hline.after=NULL,add.to.row=list(pos=list(10),command=c('\\midrule \n')),sanitize.text.function=function(x) x)
@

\bottomrule
\end{tabu}
\label{ch4:tab-rank}
\end{table}

\begin{figure}

<<ch4-rank-fig,echo=FALSE, include=TRUE,results='hide',fig.width=10.7,fig.height=8.3>>=
dt.1 <- rbind(eps.accu[,based:='EPS'],pt.accu[,based:='TP'])
plot.data <- dt.1[variable!='true',mean(value),by=.(q.id,variable,based)]
ggplot(plot.data,aes(x=as.Date(q.id),y=V1,group=variable,color=variable))+geom_smooth(method='loess',se=F,size=1L)+facet_grid(based~.,scales='free_y')+theme_bw()+theme(plot.title = element_text(colour = "Black"),legend.position='top',legend.title=element_blank(),strip.text=element_text(size=20),text=element_text(size=20,family='Times'),strip.text.y = element_text(angle = 0))+ylab(expression(paste('Average ',rho)))+xlab('Quarters')+ggtitle('Average Spearman correlation (smoothed series)')


@
\caption{Average Spearman correlation ($\rho$)}
\ The figure plots the smoothed series of the average Spearman correlation between \tr{} and predicted rankings resulted from static and dynamic states of variables: \last{} is the state with no dynamics in values of the variables, \diff{} is the state with first-difference in values, \random{} is the state that captures the random part of values time-series decomposition,  and \rollsd{} is the state of values sliding 8 quarters standard deviation. Smoothing  is done by applying a local polynomial regression fitting (loess smoothing)~\citep{cleveland1992}. The top panel shows results of rankings based on the EPS forecast accuracy, the bottom are based on the price target accuracy.
\label{ch4:fig-accur}
\end{figure}


\begin{table}
  \caption{Trading strategy performance}
  \label{ch4-tab:strategy}
  \ The table presents the annualized cumulative statistics of the strategy performance based on PT rankings. \true{} is actual ranking of the analysts. \naive{} is the rankings from the last period. \default{} is the average rank of an analyst for up to the last period. Trading period is from  \Sexpr{gsub('[[:space:]]','',final.bl[,head(Quarters,1)])} until \Sexpr{gsub('[[:space:]]','',final.bl[,tail(Quarters,1)])}. Panel A presents the results from the passive strategy. Panel B summarizes the results of the strategy with rankings based on consensus in price targets. Panel C shows the case  of the strategy with rankings based on price targets. State \last{} is the state with no dynamics in values of the variables; \diff{} is the state with first-difference in values; \random{} is the state that captures the random part of values time-series decomposition;  and \rollsd{} is the state of values sliding 8 quarters standard deviation.
  \begin{tabularx}{\linewidth}{r*{5}{Y}}
    \toprule
<<ch4-bl-market,echo=F,results='asis'>>=
results.final <- bl.results[8,1,,1]
cat(paste(c('Strategy','Annualized cum. return (in \\%)','Annualized Std. dev (in \\%)','Sharpe ratio' ,'Average num. stock','Average turnover rate'), collapse = "&"),'\\\\')
#cat('\\multicolumn{5}{l}{\\textbf{Panel A: Market}} \n')
print(xtable(t(data.table('\\textit{Market}'=results.final)),display=c('s','f','f','f','d','f'),digits=3,align=c('r',rep('c',length(results.final)))),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\midrule \n','\\multicolumn{5}{l}{\\textbf{Panel A}} \\\\ \n')),sanitize.text.function = function(x) x)
@
  \end{tabularx}
\begin{tabularx}{\linewidth}{r*{5}{Y}}
    \midrule
    \multicolumn{5}{l}{\textbf{Panel B: CONS}} \\
    \midrule
<<ch4-bl-con,echo=F,results='asis'>>=
results.final <- bl.results[2:3,1,,con]
rownames(results.final) <- paste0('\\',gsub('[[:punct:]]|[[:digit:]]','',c(baselines[2:3])),'{}')
print(xtable(results.final,display=c('s','f','f','f','d','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),sanitize.text.function = function(x) x)
@
  \end{tabularx}

\begin{tabularx}{\linewidth}{r*{5}{Y}}
    \midrule
    \multicolumn{5}{l}{\textbf{Panel C: TP}} \\
    \midrule
<<ch4-bl-pt,echo=F,results='asis'>>=
results.final <- bl.results[1:7,1,,tp]
rownames(results.final) <- paste0('\\',gsub('[[:punct:]]|[[:digit:]]','',c(baselines,methods)),'{}')
print(xtable(results.final,display=c('s','f','f','f','d','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}
%'   \begin{tabularx}{\linewidth}{r*{5}{Y}}
%'     \midrule
%'     \multicolumn{5}{l}{\textbf{Panel D: EPS}} \\
%'     \midrule
%' <<ch4-bl-eps,echo=F,results='asis'>>=
%' results.final <- bl.results[1:7,1,,eps]
%' rownames(results.final) <- paste0('\\',gsub('[[:punct:]]|[[:digit:]]','',c(baselines,methods)),'{}')
%' print(xtable(results.final,display=c('s','f','f','f','d','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),sanitize.text.function = function(x) x)
%' @
%'     \bottomrule
%'   \end{tabularx}
%\end{table}



\begin{landscape}
\begin{table}
%\small\addtolength{\tabcolsep}{-2pt}
\caption{Trading strategy performance: Sharpe ratio}
\label{ch4-tab:substrategy}
\ This table presents the Sharpe ratio of each of the trading strategies: the passive (\textit{Market}) and the active (consensus and smart estimates) calculated for different holding periods. Panel A represents the perfect foresight information set; panels B and C show, respectively, the recent and the all history analysts' performance. State \last{} is the state with no dynamics in values of the variables, \diff{} is the state with first-difference in values, \random{} is the state that captures the random part of values time-series decomposition,  and \rollsd{} is the state of values sliding 8 quarters standard deviation.

\begin{tabu} to \linewidth{r*{9}{Y}}
\toprule

%<<ch4-sr-con,echo=F,results='asis'>>=
%cat(c('Periods','&',paste0('\\',gsub('[[:punct:]]|[[:digit:]]','',c(baselines,methods,'market')),'{}',collapse = "&"),'\\\\'))
%cat('\\midrule')
%print(xtable(periods.array[,1,,'yes','sr',con],display=c('s',rep('f',8)),digits=3),only.contents=T,include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\multicolumn{9}{l}{\\textbf{Panel A: \\textit{CONS}}} \\\\\n','\\midrule \n')))
%@
%\midrule
%\end{tabu}


%\begin{tabu} to \linewidth{r*{9}{Y}}
<<ch4-sr-tp,echo=F,results='asis'>>=
cat(c('Periods','&',paste0('\\',gsub('[[:punct:]]|[[:digit:]]','',c('Market',baselines,methods)),'{}',collapse = "&"),'\\\\'))
cat('\\midrule')
print(xtable(periods.array[,1,c(8,1:7),'yes','sr',tp],display=c('s',rep('f',8)),digits=3),only.contents=T,include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(6),command=c('\\midrule \n')))
@
 \bottomrule
 \end{tabu}
 \end{table}
\end{landscape}
%'
%'  \begin{tabu} to \linewidth{r*{9}{Y}}
%'  <<ch4-sr-eps,echo=F,results='asis'>>=
%'  print(xtable(periods.array[,1,,'yes','sr',eps],display=c('s',rep('f',8)),digits=3),only.contents=T,include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\multicolumn{9}{l}{\\textbf{Panel C: \\textit{EPS}}} \\\\\n','\\midrule \n')))
%'  @
%' \bottomrule
%' \end{tabu}


\begin{landscape}
\begin{table}
\caption{Significance of cumulative returns}
\label{ch4:tab-sig}
\ The table demonstrates a pairwise  test in difference of the cumulative returns of all strategies vs. those based on the predicted rankings.  Case of \tr{} shows  the known future information; \naive{} is the case of ranking information know at $t-1$, and the \default{} is the case of using all ranking information for up to $t-1$. State \last{} is the state with no dynamics in values of the variables, \diff{} is the state with first-difference in values, \random{} is the state that captures the random part of values time-series decomposition,  and \rollsd{} is the state of values sliding 8 quarters standard deviation.
\begin{tabularx}{\linewidth}{l*{9}{Y}}
  \toprule
  &\multicolumn{2}{c}{\last{}}&\multicolumn{2}{c}{\diff{}}&\multicolumn{2}{c}{\random{}}&\multicolumn{2}{c}{\rollsd{}}\\
  &t value& Pr$(>\vert t\vert)$ & t value & Pr$(>\vert t\vert)$&t value& Pr$(>\vert t\vert)$ & t value & Pr$(>\vert t\vert)$\\
\midrule
<<ch4-t-stat,echo=F,results='asis'>>=
dimnames(t.stat.last)[[1]] <- c('\\tr{}','\\naive{}','\\default{}','\\last{}','\\diff{}','\\random{}','\\rollsd{}','\\Market{}')

print(xtable(acast(melt(t.stat.last),Var1~Var2+Var3),display=c('s',rep('f',8)),digits=3),only.contents=T,include.rownames=T,NA.string='-',include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}
\end{landscape}

\begin{figure}
<<ch4-bl-results-fig,echo=FALSE, include=TRUE,results='hide',fig.width=10.7,fig.height=8.3>>=
ggplot(final.bl[Views!='EPS'],aes(x=as.Date(Quarters),y=cum.ret,group=Method,color=Method))+geom_line(size=1)+facet_wrap(~Views,scale='free_x')+ylab('Portfolio wealth (initial=$100)')+xlab('Quarters')+ggtitle('Portfolio performance with $100 initial investment')+theme_bw()+theme(plot.title = element_text(colour = "Black"),legend.position='top',legend.title=element_blank(),strip.text=element_text(size=20),text=element_text(size=20,family='Times'))+geom_hline(yintercept=100)
@
\caption{Performance of BL model}
\label{ch4-fig:bl-results}
\ In this figure we show the quarterly performance of the cumulative portfolio wealth for all strategies.  State \last{} is the state with no dynamics in values of the variables, \diff{} is the state with first-difference in values, \random{} is the state that captures the random part of values time-series decomposition,  and \rollsd{} is the state of values sliding 8 quarters standard deviation.
\end{figure}
